[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AQUA-d Forum",
    "section": "",
    "text": "1 Willkommen üëãüèº\nHier finden sich\n\nVideos,\nAufgaben,\nDaten und\nCode\n\nf√ºr die asynchrone Vorbereitung der Sitzung Regression 01 im AQUA-d Forum des SoSe 24. Ich bitte euch alle vorab das Kapitel Einfache und multiple lineare Regression durchzuarbeiten, also die Videos zu rezipieren, die Worked Out Examples durchzugehen und die Aufgaben zu bearbeiten.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Willkommen üëãüèº</span>"
    ]
  },
  {
    "objectID": "regression.html",
    "href": "regression.html",
    "title": "2¬† Einfache und Multiple lineare Regression",
    "section": "",
    "text": "2.1 Einfache lineare Regression\nIn diesem Unterkapitel soll in die einfache lineare Regression eingef√ºhrt werden. Dazu dient ein Erkl√§rvideo gefolgt von Aufgaben.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Einfache und Multiple lineare Regression</span>"
    ]
  },
  {
    "objectID": "regression.html#einfache-lineare-regression",
    "href": "regression.html#einfache-lineare-regression",
    "title": "2¬† Einfache und Multiple lineare Regression",
    "section": "",
    "text": "2.1.1 Erkl√§rvideo\n\n\n\n\n\n\n\n\n\n\n\nDatengrundlage\n\n\n\n\n\nWir werden in diesen Workshop mit den Scientific Usefiles des STAR-Projektes (Achilles u.¬†a. 1985) arbeiten. Im STAR-Projekt standen die folgenden Forschungsfragen im Vordergrund:\n\nWhat are the effects of a reduced class size on the achievement (normed and criterion tests) and development (self-concept, attendance, etc.) of students in public elementary school grades (K-3)?\nIs there a cumulative effects of being in a small class over an extended time (4 years) as compared with a one-year effect for students in a small class for one year?\nDoes a training program designed to help teachers take maximum advantage of small classes, or to use aides effectively, improve student performance as compared with teachers who have no special preparation for their altered conditions?\n\nDie entsprechenden Variablenbezeichnungen sowie die Kodierung der Variablenauspr√§gungen werden in den jeweiligen Beispielen beschrieben.\n\n\n\n\n\n2.1.2 Worked Out Example\nIm ersten Worked Out Example wollen wir der Frage nachgehen, inwiefern die tats√§chliche Klassengr√∂√üe mit der Leistung in einem standardisierten Mathematiktest assoziiert ist.\n\n2.1.2.1 Plot\nIn einem ersten Schritt (der ganz generell immer zu empfehlen ist) plotten wir die Rohdaten. Um keine Probleme mit geclusterten Daten zu bekommen, verwenden wir aus jeder Klasse nur eine:n zuf√§llig gezogenen Sch√ºler:in. Ein .sav-file, das die notwendigen Variablen enth√§lt, kann hier heruntergeladen werden.\n\nlibrary(sjPlot)\nlibrary(bayestestR)\n\n# read the aggregated data\ndata_star_g3aggregated &lt;- read_spss(\"data/data_star_sampled.sav\")\n\n# plot rawdata\nggplot(data_star_g3aggregated,                       # the used data set\n       aes(g3classsize, g3tmathss)) +                # define x- and y-axis\n    geom_jitter() +                                  # add jittered points\n    geom_rug(position = position_jitter(), \n             alpha = .2) +                           # add rug at margins\n    stat_smooth(method = \"linear\", se = F) +                 # add linear smoother\n    theme_minimal()                                  # make appearance \"clearer\"\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 33 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Computation failed in `stat_smooth()`.\nCaused by error in `get()`:\n! object 'linear' of mode 'function' was not found\n\n\nWarning: Removed 33 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n2.1.2.2 Nicht-Standardisierte Regression\nUm nun eine einfache lineare Regression zu sch√§tzen, verwendet man in R die lm() Syntax. Links der Tilde ~ steht die abh√§ngige Variable, rechts davon die unabh√§ngige.\n\nmod00 &lt;- lm(g3tmathss ~ g3classsize, \n            data = data_star_g3aggregated)\n\nEine √úbersicht √ºber das Modell bekommt man, wenn man das Objekt mod00 der der Funktion summary() √ºbergibt.\n\nsummary(mod00)\n\n\nCall:\nlm(formula = g3tmathss ~ g3classsize, data = data_star_g3aggregated)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-122.777  -29.052   -2.627   26.348  158.723 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 647.6775    11.4121  56.754   &lt;2e-16 ***\ng3classsize  -1.3500     0.5524  -2.444   0.0151 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 43.34 on 301 degrees of freedom\n  (33 observations deleted due to missingness)\nMultiple R-squared:  0.01946,   Adjusted R-squared:  0.0162 \nF-statistic: 5.973 on 1 and 301 DF,  p-value: 0.0151\n\n\nDie (lineare) Funktionsgleichung kann man sich mit der Funktion extract_eq() aus dem Paket equatiomatic ausgeben lassen. Mit der Option use_coefs = T setzt man die gesch√§tzten Werte f√ºr die Parameter ein.\n\nlibrary(equatiomatic)\nextract_eq(mod00)\n\n\\[\n\\operatorname{g3tmathss} = \\alpha + \\beta_{1}(\\operatorname{g3classsize}) + \\epsilon\n\\]\n\nextract_eq(mod00, use_coefs = T)\n\n\\[\n\\operatorname{\\widehat{g3tmathss}} = 647.68 - 1.35(\\operatorname{g3classsize})\n\\]\n\n\nDer Steigungskoeffizient betr√§gt \\(\\approx .90\\). Unterscheiden sich zwei Klassen um eine:n Sch√ºler:in sch√§tzt das Modell die Differenz im Mathematikscore auf \\(-.90\\). Das Intercept wird auf \\(638.9\\) gesch√§tzt. Eine (hypothetische) Klasse mit 0 Sch√ºler:innen h√§tte also einen durchschnittlichen Mathematikleistungsscore von \\(638.9\\).\nDie drei Sternchen am rechten Rand des summary() Outputs zeigen an, dass die p-Werte f√ºr die Punktnullhypothesen \\[\nH_0\\text{: Intercept} = 0\n\\] \\[\nH_0\\text{: Slope} = 0\n\\] signifikant sind. Es macht also Sinn diese zu verwerfen.\n\n\n2.1.2.3 Standardisierte Regression\nEine standardisierte lineare Regression setzt wie im Video erkl√§rt voraus, dass alle Variablen z-standardisiert sind. Liegen unvollst√§ndige Daten vor, ist es wichtig diese Standardisierung erst nach dem fallweisen Ausschluss dieser fehlenden Daten vorzunehmen.\n\nmod01 &lt;- lm(scale(g3tmathss) ~ scale(g3classsize), \n            data = data_star_g3aggregated |&gt; \n                # filter rows if g3tmathss or g3classsize is NA\n                filter(!(is.na(g3tmathss) | is.na(g3classsize))))\nsummary(mod01)\n\n\nCall:\nlm(formula = scale(g3tmathss) ~ scale(g3classsize), data = filter(data_star_g3aggregated, \n    !(is.na(g3tmathss) | is.na(g3classsize))))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.8100 -0.6649 -0.0601  0.6030  3.6327 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)         1.157e-15  5.698e-02   0.000   1.0000  \nscale(g3classsize) -1.395e-01  5.708e-02  -2.444   0.0151 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9919 on 301 degrees of freedom\nMultiple R-squared:  0.01946,   Adjusted R-squared:  0.0162 \nF-statistic: 5.973 on 1 and 301 DF,  p-value: 0.0151\n\nextract_eq(mod01, use_coefs = T)\n\n\\[\n\\operatorname{\\widehat{scale(g3tmathss)}} = 0 - 0.14(\\operatorname{scale(g3classsize)})\n\\]\n\n\nDas Intercept wird auf einen Wert mit 14 Nullen nach dem Komma gesch√§tzt, ist also erwartungskonform quasi gleich null und nicht-signifikant. Der Steigungskoeffizient betr√§gt \\(\\approx .20\\) und liegt nach den Cohen Benchmarks (Cohen 1988) im Bereich kleiner bis moderater Effekte.\nEs gibt Pakete, die darauf spezialisiert sind (mehrere) Regressionsmodelle zusammengefasst √ºbersichtlich in Tabellen darzustellen. Mit der folgenden Syntax bekommt man etwa nicht nur standardisierte und unstandardisierte Koeffizienten, sondern auch deren Konfidenzintervalle, beides auf eine sinnvolle Nachkommestellenanzahl gerundet:\n\nlibrary(sjPlot)\ntab_model(mod00, show.ci = .95, show.std = T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†\nTOTAL MATH SCALE SCORE\nSAT GRADE 3\n\n\nPredictors\nEstimates\nstd. Beta\nCI\nstandardized CI\np\n\n\n(Intercept)\n647.68\n-0.00\n625.22¬†‚Äì¬†670.14\n-0.11¬†‚Äì¬†0.11\n&lt;0.001\n\n\nCLASS SIZE GRADE 3\n-1.35\n-0.14\n-2.44¬†‚Äì¬†-0.26\n-0.25¬†‚Äì¬†-0.03\n0.015\n\n\nObservations\n303\n\n\nR2 / R2 adjusted\n0.019 / 0.016",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Einfache und Multiple lineare Regression</span>"
    ]
  },
  {
    "objectID": "regression.html#aufgabe",
    "href": "regression.html#aufgabe",
    "title": "2¬† Einfache und Multiple lineare Regression",
    "section": "2.2 Aufgabe",
    "text": "2.2 Aufgabe\n\nAufgabeL√∂sungshinweiseL√∂sung\n\n\nDas STAR-Experiment variierte die Klassengr√∂√üen experimentell in K, G1, G2, G3 & G4. Daten wurden aber bis zu High School erhoben.\nDie Variable g4tmathss etwa erfasst die Mathematikleistung in Klasse 4, die Variablen g4pteffr und g4ptvalu den von Lehrkr√§ften eingesch√§tzte schulische Leistungsbereitschaft bzw. die Wertsch√§tzung schulischer Inhalte.\nWie gro√ü sch√§tzt ihr die Effekte der Pr√§diktoren g4pteffr und g4ptvalu ein? Berechnet die standardisierten und nicht-standardisierten Regressionsmodelle und diskutiert die interne, externe und Konstruktvalidit√§t der so erhaltenen Befunde.\n\n\n\nlibrary(haven)\nlibrary(sjPlot)\ndata_star_sampled &lt;- read_spss(\"data/data_star_sampled.sav\")\n\nmod02 &lt;- lm(g4tmathss ~ g4pteffr, data = data_star_sampled)\nmod03 &lt;- lm(g4tmathss ~ g4ptvalu, data = data_star_sampled)\n\ntab_model(mod02, mod03, show.std = T, show.ci = F)\n\n\n\n\ntab_model(mod02, mod03, show.std = T, show.ci = F)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†\nTOTAL MATH SCALE SCORE\nCTBS GRADE 4\nTOTAL MATH SCALE SCORE\nCTBS GRADE 4\n\n\nPredictors\nEstimates\nstd. Beta\np\nEstimates\nstd. Beta\np\n\n\n(Intercept)\n566.23\n-0.00\n&lt;0.001\n516.75\n-0.00\n&lt;0.001\n\n\nGRADE 4 PARTICIPATION\nSUBSCORE: EFFORT\n2.96\n0.68\n&lt;0.001\n\n\n\n\n\nGRADE 4 PARTICIPATION\nSUBSCORE: VALUE\n\n\n\n14.92\n0.58\n&lt;0.001\n\n\nObservations\n97\n97\n\n\nR2 / R2 adjusted\n0.467 / 0.461\n0.337 / 0.330\n\n\n\n\n\n\n\n\nDer standardisierte Regressionskoeffizient der Effort-Skala ist mit .58 enorm gro√ü ausgepr√§gt und auch der Effekt des Pr√§diktors value ist substantiell. Beachtet werden muss allerdings, dass die p-Werte nichts √ºber die Sicherheit der Unterschiedlichkeit der beiden Steigungsparameter aussagt. Getestet wurde jeweils wieder nur die Nullhypothese eines Nulleffekts. Zu kritisieren sind hier sicher interne und Konstruktvalidit√§t. Effort und Value der Sch√ºler:innen wurden von den Lehrkr√§ften ohne vorherige Raterschulung eingesch√§tzt. Daher ist anzunehmen, dass dieses Rating auch durch die Leistung der Sch√ºler:innen verzerrt ist (z.B. im Sinne eines Haloeffekts, Dennis 2007). Die interne Validit√§t der Schlussfolgerung aus diesen Regressionsmodellen ist schwach, da es sich nur um querschnittliche Daten handelt und die Auspr√§gung der unabh√§ngigen Variable nicht randomisiert wurde.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Einfache und Multiple lineare Regression</span>"
    ]
  },
  {
    "objectID": "regression.html#multiple-lineare-regression",
    "href": "regression.html#multiple-lineare-regression",
    "title": "2¬† Einfache und Multiple lineare Regression",
    "section": "2.3 Multiple lineare Regression",
    "text": "2.3 Multiple lineare Regression\nIn diesem Unterkapitel soll in die multiple Regression eingef√ºhrt werden. Dazu dient ebenfalls ein Erkl√§rvideo gefolgt von Aufgaben.\n\n2.3.1 Erkl√§rvideo\n\n\n\n\n\n\n\n2.3.2 Erkl√§rvideo\nDie standardisierten Steigungskoeffizeinten \\(\\beta_i\\) stellen ja eine Effektst√§rke der partiellen Assoziation des Pr√§diktors \\(i\\) mit der abh√§ngigen Variable dar. Nimmt man mehrere Pr√§diktoren auf, kann der Determinationskoeffizient \\(R^2\\) eine Effektst√§rke f√ºr die G√ºte des Gesamtmodells darstellen.\n\n\n\n\n\n\n\n2.3.3 Worked Out Example\nIn der √úbungsaufgabe zur einfachen linearen Regression haben wir vermutet, dass Einsch√§tzung von Effort und Value durch die Lehrkraft von der Leistung der Lernenden gef√§rbt sein k√∂nnte. W√§re dem so, sollte man ein Sinken der Pr√§diktionskraft des Pr√§diktors Value nach Adjustierung um die Vorjahresleistung beobachten.\n\ntab_model(\n    lm(g4tmathss ~ g4ptvalu, data = data_star_sampled),\n    lm(g4tmathss ~ g4ptvalu + g3tmathss, data = data_star_sampled),\n    show.ci = F, show.std = T\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†\nTOTAL MATH SCALE SCORE\nCTBS GRADE 4\nTOTAL MATH SCALE SCORE\nCTBS GRADE 4\n\n\nPredictors\nEstimates\nstd. Beta\np\nEstimates\nstd. Beta\np\n\n\n(Intercept)\n516.75\n-0.00\n&lt;0.001\n215.13\n0.00\n&lt;0.001\n\n\nGRADE 4 PARTICIPATION\nSUBSCORE: VALUE\n14.92\n0.58\n&lt;0.001\n8.33\n0.32\n&lt;0.001\n\n\nTOTAL MATH SCALE SCORE\nSAT GRADE 3\n\n\n\n0.62\n0.54\n&lt;0.001\n\n\nObservations\n97\n94\n\n\nR2 / R2 adjusted\n0.337 / 0.330\n0.552 / 0.542\n\n\n\n\n\n\n\n\nDies ist tats√§chlich der Fall. Der standardisierte Regressionskoeffizient sinkt von .35 auf .12.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Einfache und Multiple lineare Regression</span>"
    ]
  },
  {
    "objectID": "regression.html#aufgabe-2",
    "href": "regression.html#aufgabe-2",
    "title": "2¬† Einfache und Multiple lineare Regression",
    "section": "2.4 Aufgabe",
    "text": "2.4 Aufgabe\n\nAufgabeL√∂sungshinweiseL√∂sung\n\n\nUntersucht, inwiefern die ebenfalls Lehrer:inneingesch√§tzte Variable Initiative (z.B. ‚Äúparticipates actively in class discussions‚Äù) g4ptinit die Mathematikleistung in Klasse 4 g4tmathss pr√§diziert und inwiefern sich der Effekt nach Adjustierung der Vortestleistung g3tmathss √§ndert\n\n\n\nlm(g4tmathss ~ g4ptinit, data = data_star_sampled)\nlm(g4tmathss ~ g4ptinit + g3tmathss, data = data_star_sampled)\n\n\n\n\ntab_model(\n    lm(g4tmathss ~ g4ptinit, data = data_star_sampled),\n    lm(g4tmathss ~ g4ptinit + g3tmathss, data = data_star_sampled),\n    show.std = T, show.ci = F)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†\nTOTAL MATH SCALE SCORE\nCTBS GRADE 4\nTOTAL MATH SCALE SCORE\nCTBS GRADE 4\n\n\nPredictors\nEstimates\nstd. Beta\np\nEstimates\nstd. Beta\np\n\n\n(Intercept)\n597.86\n-0.00\n&lt;0.001\n278.49\n-0.00\n&lt;0.001\n\n\nGRADE 4 PARTICIPATION\nSUBSCORE: INITIATIVE\n4.26\n0.59\n&lt;0.001\n2.01\n0.28\n0.002\n\n\nTOTAL MATH SCALE SCORE\nSAT GRADE 3\n\n\n\n0.60\n0.53\n&lt;0.001\n\n\nObservations\n97\n94\n\n\nR2 / R2 adjusted\n0.352 / 0.345\n0.521 / 0.510\n\n\n\n\n\n\n\n\nDer standardisierte Regressionskoeffizient der Initiative-Skala ist mit .49 gro√ü ausgepr√§gt. Nach Adjustierung um die Vorjahrestestleistung, sinkt die pr√§diktive Kraft deutlich, es ist aber weiterhin ein substantieller Effekt zu beobachten.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Einfache und Multiple lineare Regression</span>"
    ]
  },
  {
    "objectID": "regression.html#weiterf√ºhrende-literatur",
    "href": "regression.html#weiterf√ºhrende-literatur",
    "title": "2¬† Einfache und Multiple lineare Regression",
    "section": "2.5 Weiterf√ºhrende Literatur",
    "text": "2.5 Weiterf√ºhrende Literatur\n\n\n\n\n\n\nLiteraturempfehlungen zum Thema Regression\n\n\n\n\n\n\nEid, M., Gollwitzer, M., & Schmitt, M. (2013). Statistik und Forschungsmethoden: Lehrbuch. Mit Online-Materialien (3. Aufl.). Beltz.\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and Other Stories (1. Aufl.). Cambridge University Press. https://doi.org/10.1017/9781139161879\n\n\n\n\n\n\n\n\nAchilles, C. M., Helen Pate Bain, F. Bellot, J. Boyd-Zaharias, J. Finn, J. Folger, John Johnston, und Elizabeth Word. 1985. ‚ÄûThe State of Tennessee‚Äôs Student/Teacher Achievement Ratio (STAR) Project‚Äú. Technical {{Report}}. Tennessee State Department of Educatbn.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral Sciences. 2. Aufl. New Jersey: Lawrence Erlbaum.\n\n\nDennis, Ian. 2007. ‚ÄûHalo Effects in Grading Student Projects‚Äú. Journal of Applied Psychology 92 (4): 1169‚Äì76. https://doi.org/10.1037/0021-9010.92.4.1169.\n\n\nMoosbrugger, Helfried. 2011. Lineare Modelle: Regressions- und Varianzanalysen ; mit einem Anhang √ºber Matrixalgebra. 4., vollst√§ndig √ºberarbeitete und erg√§nzte Auflage. Psychologie Lehrtexte. Bern: Verlag Hans Huber.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Einfache und Multiple lineare Regression</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literatur",
    "section": "",
    "text": "Achilles, C. M., Helen Pate Bain, F. Bellot, J. Boyd-Zaharias, J. Finn,\nJ. Folger, John Johnston, and Elizabeth Word. 1985. ‚ÄúThe State of\nTennessee‚Äôs Student/Teacher Achievement Ratio\n(STAR) Project.‚Äù Technical {{Report}}.\nTennessee State Department of Educatbn.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral\nSciences. 2nd ed. New Jersey: Lawrence\nErlbaum.\n\n\nDennis, Ian. 2007. ‚ÄúHalo Effects in Grading Student\nProjects.‚Äù Journal of Applied Psychology 92 (4):\n1169‚Äì76. https://doi.org/10.1037/0021-9010.92.4.1169.\n\n\nMoosbrugger, Helfried. 2011. Lineare Modelle: Regressions- und\nVarianzanalysen ; mit einem Anhang √ºber\nMatrixalgebra. 4., vollst√§ndig\n√ºberarbeitete und erg√§nzte Auflage.\nPsychologie Lehrtexte. Bern: Verlag Hans\nHuber.",
    "crumbs": [
      "Literatur"
    ]
  },
  {
    "objectID": "regression_assumptions.html",
    "href": "regression_assumptions.html",
    "title": "3¬† Annahmen f√ºr die Inferenzstatistik (Regressionsdiagnostik)",
    "section": "",
    "text": "3.1 Parameter, Effektst√§rken und Inferenzstatistiken\nWir haben nun die Parametrisierung der multiplen linearen Regression kennengelernt und dazu die folgenden Parameter, Effektst√§rken und Inferenzstatistiken kennengelernt:",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Annahmen f√ºr die Inferenzstatistik (Regressionsdiagnostik)</span>"
    ]
  },
  {
    "objectID": "regression_assumptions.html#parameter-effektst√§rken-und-inferenzstatistiken",
    "href": "regression_assumptions.html#parameter-effektst√§rken-und-inferenzstatistiken",
    "title": "3¬† Annahmen f√ºr die Inferenzstatistik (Regressionsdiagnostik)",
    "section": "",
    "text": "Parameter:\n\nIntercept der Regression \\(b_0\\)\nSlope der Regression \\(b_1\\)\n\nEffektst√§rken:\n\nSlope der standardisierten Regression \\(\\beta_1\\)\nDeterminationskoeffizient \\(R^2\\)\n\nInferenzstatistiken:\n\n\\(p\\)-Werte f√ºr Parameter (Typische \\(H_0\\text{: }\\;b_i = 0\\))\n\\(p\\)-Werte f√ºr \\(R^2\\) (Typische \\(H_0\\text{: }\\;R^2 = 0\\) oder \\(H_0\\text{: }\\;R^2_{Modell_1} = R^2_{Modell_2}\\))\n\\(BF\\)-Werte f√ºr \\(R^2\\) (Typische \\(H_0\\text{: }\\;R^2 = 0\\) oder \\(H_0\\text{: }\\;R^2_{Modell_1} = R^2_{Modell_2}\\))\nKonfidenzintervalle f√ºr Parameter\nBayesian Credibility Intervalle f√ºr Parameter",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Annahmen f√ºr die Inferenzstatistik (Regressionsdiagnostik)</span>"
    ]
  },
  {
    "objectID": "regression_assumptions.html#annhamen",
    "href": "regression_assumptions.html#annhamen",
    "title": "3¬† Annahmen f√ºr die Inferenzstatistik (Regressionsdiagnostik)",
    "section": "3.2 Annhamen",
    "text": "3.2 Annhamen\nDie Verfahren zur Berechnung der Inferenzstatistiken treffen Annahmen √ºber den datengenerierenden Mechanismus. Sind diese verletzt, kann man die Inferenzstatistiken dennoch berechnen, sie sind aber nicht mehr aussagekr√§ftig - √§hnlich wie man auch in einem nicht rechtwinkligen Dreieck \\(a^2 + b^2\\) berechnen kann, diese Summe aber nicht \\(c^2\\) ergibt. So wie man also vor der Anwendung des Satz des Pythagoras \\(a^2 + b^2 = c^2\\) pr√ºfen muss, ob das Dreick rechtwinklig ist, muss man vor der Berechnung der Inferenzstatistiken deren Voraussetzungen pr√ºfen.\nZur Definition der Voraussetzungen von inferenzstatistischen Verfahren wird meist zun√§chst ein Populationsmodell spezifiziert um dann zus√§tzliche Annahmen f√ºr die Sch√§tzung anzugeben. Das Populationsmodell der multiplen linearen Regression lautet:\n\\[\n\\begin{aligned}\nY= & E\\left(Y \\mid X_1, \\ldots, X_k\\right)+\\varepsilon=\\beta_0+\\beta_1 \\cdot X_1+\\beta_2 \\cdot X_2 \\\\\n& +\\ldots+\\beta_j \\cdot X_j+\\ldots+\\beta_k \\cdot X_k+\\varepsilon\n\\end{aligned}\n\\] Dabei stellt \\(E\\left(Y \\mid X_1, \\ldots, X_k\\right)\\) den bedingten Erwartungswert von Y dar.\n\n\n\n\n\n\nWichtig\n\n\n\n\n\nF√ºr die Sch√§tzung der Parameter wird meist zus√§tzlich angenommen:\n\nHomoskedastizit√§t: \\(\\operatorname{Var}(Y \\mid X)=\\operatorname{Var}(\\varepsilon \\mid X)=\\sigma_{\\varepsilon}^2\\). Die Streuung der Residuen muss also f√ºr verschiedene Pr√§diktorwerte konstant sein.\nBedingte Normalverteilung: \\(\\varepsilon_i \\sim N\\left(\\mu_i, \\sigma_{i}^2\\right)\\). Die Residuen m√ºssen normalverteilt sein\nUnabh√§ngigkeit der Residuen: \\(\\varepsilon_i \\sim \\text{i.i.d.}\\). Die Residuen ¬ªd√ºrfen keine Information teilen¬´.\n\n\n\n\nDiese Annahmen sind nach dem Satz von Gau√ü Markov zu \\(\\forall i: \\varepsilon_i \\sim\\left(0, \\sigma^2\\right)\\) abschw√§chbar. Da dies aber weniger anschaulich ist bleiben wir bei den erstgenannten Annahmen.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Annahmen f√ºr die Inferenzstatistik (Regressionsdiagnostik)</span>"
    ]
  },
  {
    "objectID": "regression_assumptions.html#diagnostik-der-annahmen",
    "href": "regression_assumptions.html#diagnostik-der-annahmen",
    "title": "3¬† Annahmen f√ºr die Inferenzstatistik (Regressionsdiagnostik)",
    "section": "3.3 Diagnostik der Annahmen",
    "text": "3.3 Diagnostik der Annahmen\nWie diagnostiziert man aber nun inwiefern diese Annahmen f√ºr vorliegende Daten problematisch sind? Zun√§chst: Diese sog. Regressionsdiagnostik ist wesentlich komplexer und bedarf gr√∂√üerer Expertise als das Spezifizieren, Sch√§tzen und Interpretieren der Modelle - Hilfe und Kontrolle durch kompetente Forscher:innen ist also ratsam.\n\n3.3.1 Graphische und koeffizientenbasierte Diagnostik\nPrinzipiell unterscheidet man zwischen graphischer und koeffizientenbasierter Regressionsdiagnostik. Bei ersterer versucht man aus geeigneten Grafiken die Einhaltung/Abweichung der Annahmen abzusch√§tzen - bei zweiterer berechnet man Koeffizienten welche die Abweichung von den Annahmen beschreiben.\n\n3.3.1.1 Graphische Regressionsdiagnostik\nZun√§chst plottet man eigentlich immer die Rohdaten und das gesch√§tzte Modell.\n\nlibrary(haven)\nlibrary(tidyverse)\n\n# read the aggregated data\ndata_star_g3aggregated &lt;- read_spss(\"data/data_star_sampled.sav\")\n\n# plot rawdata\nggplot(data_star_g3aggregated,                       # the used data set\n       aes(g3classsize, g3tmathss)) +                # define x- and y-axis\n    geom_jitter() +                                  # add jittered points\n    geom_rug(position = position_jitter(), \n             alpha = .2) +                           # add rug at margins\n    stat_smooth(se = F, method = \"lm\") +             # add linear smoother\n    theme_minimal()                                  # make appearance \"clearer\"\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 42 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 42 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nDas Paket {performance} liefert zudem weitere sehr heuristische Plots f√ºr die Graphische Regressionsdiagnostik:\n\nlibrary(performance)\n\n# Spezifikation und Sch√§tzung des Modells\nmod00 &lt;- lm(g3tmathss ~ g3classsize, \n            data = data_star_g3aggregated)\n\n# Grafische Regressionsdiagostik\ncheck_model(mod00)",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Annahmen f√ºr die Inferenzstatistik (Regressionsdiagnostik)</span>"
    ]
  },
  {
    "objectID": "regression_assumptions.html#annahmen",
    "href": "regression_assumptions.html#annahmen",
    "title": "3¬† Annahmen f√ºr die Inferenzstatistik (Regressionsdiagnostik)",
    "section": "3.2 Annahmen",
    "text": "3.2 Annahmen\nDie Verfahren zur Berechnung der Inferenzstatistiken treffen Annahmen √ºber den datengenerierenden Mechanismus. Sind diese verletzt, kann man die Inferenzstatistiken dennoch berechnen, sie sind aber nicht mehr aussagekr√§ftig - √§hnlich wie man auch in einem nicht rechtwinkligen Dreieck \\(a^2 + b^2\\) berechnen kann, diese Summe aber nicht \\(c^2\\) ergibt. So wie man also vor der Anwendung des Satz des Pythagoras \\(a^2 + b^2 = c^2\\) pr√ºfen muss, ob das Dreick rechtwinklig ist, muss man vor der Berechnung der Inferenzstatistiken deren Voraussetzungen pr√ºfen.\nZur Definition der Voraussetzungen von inferenzstatistischen Verfahren wird meist zun√§chst ein Populationsmodell spezifiziert um dann zus√§tzliche Annahmen f√ºr die Sch√§tzung anzugeben. Das Populationsmodell der multiplen linearen Regression lautet:\n\\[\n\\begin{aligned}\nY=\\;& E\\left(Y \\mid X_1, \\ldots, X_k\\right)+\\varepsilon=\\beta_0+\\beta_1 \\cdot X_1+\\beta_2 \\cdot X_2 \\\\\n& +\\ldots+\\beta_j \\cdot X_j+\\ldots+\\beta_k \\cdot X_k+\\varepsilon\n\\end{aligned}\n\\] Dabei stellt \\(E\\left(Y \\mid X_1, \\ldots, X_k\\right)\\) den bedingten Erwartungswert von Y dar.\n\n\n\n\n\n\nWichtig\n\n\n\n\n\nF√ºr die Sch√§tzung der Parameter wird meist zus√§tzlich angenommen:\n\nHomoskedastizit√§t: \\(\\operatorname{Var}(Y \\mid X)=\\operatorname{Var}(\\varepsilon \\mid X)=\\sigma_{\\varepsilon}^2\\). Die Streuung der Residuen muss also f√ºr verschiedene Pr√§diktorwerte konstant sein.\nBedingte Normalverteilung: \\(\\varepsilon_i \\sim N\\left(\\mu_i, \\sigma_{i}^2\\right)\\). Die Residuen m√ºssen normalverteilt sein\nUnabh√§ngigkeit der Residuen: \\(\\varepsilon_i \\sim \\text{i.i.d.}\\). Die Residuen ¬ªd√ºrfen keine Information teilen¬´.\n\n\n\n\nDiese Annahmen sind nach dem Satz von Gau√ü Markov zu \\(\\forall i: \\varepsilon_i \\sim\\left(0, \\sigma^2\\right)\\) abschw√§chbar. Da dies aber weniger anschaulich ist bleiben wir bei den erstgenannten Annahmen.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Annahmen f√ºr die Inferenzstatistik (Regressionsdiagnostik)</span>"
    ]
  },
  {
    "objectID": "regression_with_dummies.html",
    "href": "regression_with_dummies.html",
    "title": "4¬† Regression mit Dummyvariablen",
    "section": "",
    "text": "4.1 Erkl√§rvideo",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Regression mit Dummyvariablen</span>"
    ]
  },
  {
    "objectID": "regression_with_dummies.html#erkl√§rvideo",
    "href": "regression_with_dummies.html#erkl√§rvideo",
    "title": "4¬† Regression mit Dummyvariablen",
    "section": "",
    "text": "4.1.1 Worked out Example I (dichotomer Pr√§diktor)\nDer STAR-Datensatz enth√§lt die dichotome Variable g3size welche nur zwischen kleinen Klassen \"small\" und gro√üen Klassen bzw. gro√üen Klassen mit Hilfslehrkraft \"not_small\" unterscheidet. Tr√§gt man diese Variable gegen die Klassengr√∂√üe auf erh√§lt man den folgenden Plot:\n\ndata_star_g3aggregated |&gt; \n  ggplot(aes(g3size, g3classsize)) +\n  geom_jitter() +\n  theme_minimal()\n\n\n\n\n\n\n\n\nIst man nun an einem Vergleich der Mathematikleistung in den gro√üen vs.¬†den kleinen Klassen interessiert, kann man die Variable g3size als Pr√§diktor verwenden. Ein deskriptiver Plot sieht wie folgt aus:\n\ndata_star_g3aggregated |&gt; \n  ggplot(aes(g3size, g3tmathss)) + \n  geom_boxplot() +\n  geom_jitter() +\n  theme_minimal()\n\nWarning: Removed 33 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\nWarning: Removed 33 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nVerwendet man g3size als Pr√§diktor in lm() erstellt R automatisch die entsprechende Dummyvariable:\n\nmod04 &lt;- lm(g3tmathss ~ g3size, data = data_star_g3aggregated)\nsummary(mod04)\n\n\nCall:\nlm(formula = g3tmathss ~ g3size, data = data_star_g3aggregated)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-120.222  -29.722   -2.356   27.144  157.644 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  616.356      3.269 188.539   &lt;2e-16 ***\ng3sizesmall    9.866      5.070   1.946   0.0526 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 43.49 on 301 degrees of freedom\n  (33 observations deleted due to missingness)\nMultiple R-squared:  0.01243,   Adjusted R-squared:  0.009146 \nF-statistic: 3.788 on 1 and 301 DF,  p-value: 0.05256\n\n\nDieser Output ist in die folgende Regressionsgleichung √ºbersetzbar: \\[\n\\operatorname{\\widehat{g3tmathss}} = 614.52 + 12.09(\\operatorname{g3size}_{\\operatorname{small}})\n\\] Am Names des Pr√§diktors g3sizesmall kann man erkennen, dass die lm()-Funktion aus der Variable g3size eine Dummyvariable gemacht hat, die den Wert 0 hat, wenn g3size == \"not_small\" gilt (Referenzkategorie) und den Wert 1 hat, falls es sich um eine kleine Klasse handelt.\nAm Output erkennt man nun, dass die gro√üen Klassen im Durchschnitt 616.3559322 Punkte erzielen und die die kleinen Klassen 9.86629 Punkte mehr. Ist das nun ein gro√üer oder kleiner Unterschied? Diese Frage kann man auf mehrere Arten beantworten: Man kann z.B. das \\(R^2\\) betrachten oder man standardisiert (nur) die abh√§ngige Variable. Geplottet sieht das dann so aus:\n\ndata_star_g3aggregated |&gt; \n  ggplot(aes(g3size, scale(g3tmathss))) + \n  geom_boxplot() +\n  geom_jitter() +\n  theme_minimal()\n\nWarning: Removed 33 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\nWarning: Removed 33 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nMan kann hier schon die Mittelwertsdifferenz in Standardabweichungen absch√§tzen, was ja dem Cohen‚Äôs d entspricht. Das entsprechende Regressionsmodell liefert dieses ebenfalls:\n\nmod05 &lt;- lm(scale(g3tmathss) ~ g3size, data = data_star_g3aggregated)\nsummary(mod05)\n\n\nCall:\nlm(formula = scale(g3tmathss) ~ g3size, data = data_star_g3aggregated)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.7515 -0.6803 -0.0539  0.6212  3.6080 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept) -0.09390    0.07482  -1.255   0.2104  \ng3sizesmall  0.22581    0.11603   1.946   0.0526 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9954 on 301 degrees of freedom\n  (33 observations deleted due to missingness)\nMultiple R-squared:  0.01243,   Adjusted R-squared:  0.009146 \nF-statistic: 3.788 on 1 and 301 DF,  p-value: 0.05256\n\n\nDie Mittelwertsdifferenz (der Slope) liegt also bei 0.2258091. Dieses Wert erh√§lt man auch wenn man Cohen‚Äôs d berechnet:\n\nlibrary(effectsize)\ncohens_d(g3tmathss ~ g3size, data = data_star_g3aggregated)\n\nWarning: Missing values detected. NAs dropped.\n\n\nCohen's d |        95% CI\n-------------------------\n-0.23     | [-0.46, 0.00]\n\n- Estimated using pooled SD.\n\n\nManchmal ergeben sich bei dieser Berechnung kleinste Unterschiede, je nach dem wie die Standardabweichungen der beiden Gruppen gemittelt (gepoolt) werden.\n\n\n4.1.2 Worked out Example I (trichotomer Pr√§diktor)\nM√∂chte man die drei verschiedenen Gruppen des STAR-Experimentes miteinander vergleichen, setzt man in die lm() Funktion die trichotome Variable g3classtype als Pr√§diktor ein.\n\nmod06 &lt;- lm(g3tmathss ~ g3classtype, data = data_star_g3aggregated)\nsummary(mod06)\n\n\nCall:\nlm(formula = g3tmathss ~ g3classtype, data = data_star_g3aggregated)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-120.222  -29.566   -2.222   27.191  157.293 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 615.9103     4.9327 124.863   &lt;2e-16 ***\ng3classtyperegular_with_aid   0.7968     6.5956   0.121    0.904    \ng3classtypesmall             10.3120     6.2764   1.643    0.101    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 43.56 on 300 degrees of freedom\n  (33 observations deleted due to missingness)\nMultiple R-squared:  0.01248,   Adjusted R-squared:  0.005892 \nF-statistic: 1.895 on 2 and 300 DF,  p-value: 0.1521\n\n\nMan erh√§lt nun im Output zwei Pr√§diktoren, da die trichotome Variable zu einer Referenzkategrie und zwei Dummyvariablen f√ºr die zwei Unterschiede der anderen beiden Gruppen zu dieser Referenzkategorie umkodiert wurde. Demnach ist also der Mittelwert in der Referenzkategorie (regular class) gleich dem Intercept 615.9102564, der Mittelwert in den kleinen Klassen unterscheidet sich um 10.3119658 und der in Klassen mit Hilfslehrkraft um 0.7968143.\nUm bei der Interpretation keine Fehler zu machen lohnt es sich immer die Mittelwerte nochmals klassisch gegenzurechnen:\n\ndata_star_g3aggregated |&gt; \n  group_by(g3classtype) |&gt; \n  summarize(MWg3tmathss = mean(g3tmathss, na.rm = T))\n\n# A tibble: 3 √ó 2\n  g3classtype      MWg3tmathss\n  &lt;chr&gt;                  &lt;dbl&gt;\n1 regular                 616.\n2 regular_with_aid        617.\n3 small                   626.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Regression mit Dummyvariablen</span>"
    ]
  }
]