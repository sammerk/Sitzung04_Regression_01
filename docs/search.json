[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AQUA-d Forum",
    "section": "",
    "text": "1 Willkommen üëãüèº\nHier finden sich\n\nVideos,\nAufgaben,\nDaten und\nCode\n\nf√ºr die asynchrone Vorbereitung der Sitzung Regression 01 im AQUA-d Forum des SoSe 24. Ich bitte euch alle vorab das Kapitel Einfache und multiple lineare Regression durchzuarbeiten, also die Videos zu rezipieren, die Worked Out Examples durchzugehen und die Aufgaben zu bearbeiten.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Willkommen üëãüèº</span>"
    ]
  },
  {
    "objectID": "regression.html",
    "href": "regression.html",
    "title": "2¬† Einfache und Multiple lineare Regression",
    "section": "",
    "text": "2.1 Einfache lineare Regression\nIn diesem Unterkapitel soll in die einfache lineare Regression eingef√ºhrt werden. Dazu dient ein Erkl√§rvideo gefolgt von Aufgaben.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Einfache und Multiple lineare Regression</span>"
    ]
  },
  {
    "objectID": "regression.html#einfache-lineare-regression",
    "href": "regression.html#einfache-lineare-regression",
    "title": "2¬† Einfache und Multiple lineare Regression",
    "section": "",
    "text": "2.1.1 Erkl√§rvideo\n\n\n\n\n\n\n\n\n\n\n\nDatengrundlage\n\n\n\n\n\nWir werden in diesen Workshop mit den Scientific Usefiles des STAR-Projektes (Achilles u.¬†a. 1985) arbeiten. Im STAR-Projekt standen die folgenden Forschungsfragen im Vordergrund:\n\nWhat are the effects of a reduced class size on the achievement (normed and criterion tests) and development (self-concept, attendance, etc.) of students in public elementary school grades (K-3)?\nIs there a cumulative effects of being in a small class over an extended time (4 years) as compared with a one-year effect for students in a small class for one year?\nDoes a training program designed to help teachers take maximum advantage of small classes, or to use aides effectively, improve student performance as compared with teachers who have no special preparation for their altered conditions?\n\nDie entsprechenden Variablenbezeichnungen sowie die Kodierung der Variablenauspr√§gungen werden in den jeweiligen Beispielen beschrieben.\n\n\n\n\n\n2.1.2 Worked Out Example\nIm ersten Worked Out Example wollen wir der Frage nachgehen, inwiefern die tats√§chliche Klassengr√∂√üe mit der Leistung in einem standardisierten Mathematiktest assoziiert ist.\n\n2.1.2.1 Plot\nIn einem ersten Schritt (der ganz generell immer zu empfehlen ist) plotten wir die Rohdaten. Um keine Probleme mit geclusterten Daten zu bekommen, verwenden wir aus jeder Klasse nur eine:n zuf√§llig gezogenen Sch√ºler:in. Ein .sav-file, das die notwendigen Variablen enth√§lt, kann hier heruntergeladen werden.\n\nlibrary(sjPlot)\nlibrary(bayestestR)\n\n# read the aggregated data\ndata_star_g3sampled &lt;- read_spss(\"data/data_star_sampled.sav\")\n\n# plot rawdata\nggplot(data_star_g3sampled,                       # the used data set\n       aes(g3classsize, g3tmathss)) +                # define x- and y-axis\n    geom_jitter() +                                  # add jittered points\n    geom_rug(position = position_jitter(), \n             alpha = .2) +                           # add rug at margins\n    stat_smooth(method = \"linear\", se = F) +                 # add linear smoother\n    theme_minimal()                                  # make appearance \"clearer\"\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 30 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Computation failed in `stat_smooth()`.\nCaused by error in `get()`:\n! object 'linear' of mode 'function' was not found\n\n\nWarning: Removed 30 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n2.1.2.2 Nicht-Standardisierte Regression\nUm nun eine einfache lineare Regression zu sch√§tzen, verwendet man in R die lm() Syntax. Links der Tilde ~ steht die abh√§ngige Variable, rechts davon die unabh√§ngige.\n\nmod00 &lt;- lm(g3tmathss ~ g3classsize, \n            data = data_star_g3sampled)\n\nEine √úbersicht √ºber das Modell bekommt man, wenn man das Objekt mod00 der der Funktion summary() √ºbergibt.\n\nsummary(mod00)\n\n\nCall:\nlm(formula = g3tmathss ~ g3classsize, data = data_star_g3sampled)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-95.762 -25.574  -2.887  26.842 133.947 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  651.971     10.239  63.676  &lt; 2e-16 ***\ng3classsize   -1.542      0.493  -3.127  0.00194 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 39.19 on 304 degrees of freedom\n  (30 observations deleted due to missingness)\nMultiple R-squared:  0.03117,   Adjusted R-squared:  0.02798 \nF-statistic: 9.779 on 1 and 304 DF,  p-value: 0.001936\n\n\nDie (lineare) Funktionsgleichung kann man sich mit der Funktion extract_eq() aus dem Paket equatiomatic ausgeben lassen. Mit der Option use_coefs = T setzt man die gesch√§tzten Werte f√ºr die Parameter ein.\n\nlibrary(equatiomatic)\nextract_eq(mod00)\n\n\\[\n\\operatorname{g3tmathss} = \\alpha + \\beta_{1}(\\operatorname{g3classsize}) + \\epsilon\n\\]\n\nextract_eq(mod00, use_coefs = T)\n\n\\[\n\\operatorname{\\widehat{g3tmathss}} = 651.97 - 1.54(\\operatorname{g3classsize})\n\\]\n\n\nDer Steigungskoeffizient betr√§gt \\(\\approx .90\\). Unterscheiden sich zwei Klassen um eine:n Sch√ºler:in sch√§tzt das Modell die Differenz im Mathematikscore auf \\(-.90\\). Das Intercept wird auf \\(638.9\\) gesch√§tzt. Eine (hypothetische) Klasse mit 0 Sch√ºler:innen h√§tte also einen durchschnittlichen Mathematikleistungsscore von \\(638.9\\).\nDie drei Sternchen am rechten Rand des summary() Outputs zeigen an, dass die p-Werte f√ºr die Punktnullhypothesen \\[\nH_0\\text{: Intercept} = 0\n\\] \\[\nH_0\\text{: Slope} = 0\n\\] signifikant sind. Es macht also Sinn diese zu verwerfen.\n\n\n2.1.2.3 Standardisierte Regression\nEine standardisierte lineare Regression setzt wie im Video erkl√§rt voraus, dass alle Variablen z-standardisiert sind. Liegen unvollst√§ndige Daten vor, ist es wichtig diese Standardisierung erst nach dem fallweisen Ausschluss dieser fehlenden Daten vorzunehmen.\n\nmod01 &lt;- lm(scale(g3tmathss) ~ scale(g3classsize), \n            data = data_star_g3sampled |&gt; \n                # filter rows if g3tmathss or g3classsize is NA\n                filter(!(is.na(g3tmathss) | is.na(g3classsize))))\nsummary(mod01)\n\n\nCall:\nlm(formula = scale(g3tmathss) ~ scale(g3classsize), data = filter(data_star_g3sampled, \n    !(is.na(g3tmathss) | is.na(g3classsize))))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.4090 -0.6433 -0.0726  0.6752  3.3695 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)         3.978e-16  5.636e-02   0.000  1.00000   \nscale(g3classsize) -1.765e-01  5.645e-02  -3.127  0.00194 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9859 on 304 degrees of freedom\nMultiple R-squared:  0.03117,   Adjusted R-squared:  0.02798 \nF-statistic: 9.779 on 1 and 304 DF,  p-value: 0.001936\n\nextract_eq(mod01, use_coefs = T)\n\n\\[\n\\operatorname{\\widehat{scale(g3tmathss)}} = 0 - 0.18(\\operatorname{scale(g3classsize)})\n\\]\n\n\nDas Intercept wird auf einen Wert mit 14 Nullen nach dem Komma gesch√§tzt, ist also erwartungskonform quasi gleich null und nicht-signifikant. Der Steigungskoeffizient betr√§gt \\(\\approx .20\\) und liegt nach den Cohen Benchmarks (Cohen 1988) im Bereich kleiner bis moderater Effekte.\nEs gibt Pakete, die darauf spezialisiert sind (mehrere) Regressionsmodelle zusammengefasst √ºbersichtlich in Tabellen darzustellen. Mit der folgenden Syntax bekommt man etwa nicht nur standardisierte und unstandardisierte Koeffizienten, sondern auch deren Konfidenzintervalle, beides auf eine sinnvolle Nachkommestellenanzahl gerundet:\n\nlibrary(sjPlot)\ntab_model(mod00, show.ci = .95, show.std = T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†\nTOTAL MATH SCALE SCORE\nSAT GRADE 3\n\n\nPredictors\nEstimates\nstd. Beta\nCI\nstandardized CI\np\n\n\n(Intercept)\n651.97\n0.00\n631.82¬†‚Äì¬†672.12\n-0.11¬†‚Äì¬†0.11\n&lt;0.001\n\n\nCLASS SIZE GRADE 3\n-1.54\n-0.18\n-2.51¬†‚Äì¬†-0.57\n-0.29¬†‚Äì¬†-0.07\n0.002\n\n\nObservations\n306\n\n\nR2 / R2 adjusted\n0.031 / 0.028",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Einfache und Multiple lineare Regression</span>"
    ]
  },
  {
    "objectID": "regression.html#aufgabe",
    "href": "regression.html#aufgabe",
    "title": "2¬† Einfache und Multiple lineare Regression",
    "section": "2.2 Aufgabe",
    "text": "2.2 Aufgabe\n\nAufgabeL√∂sungshinweiseL√∂sung\n\n\nDas STAR-Experiment variierte die Klassengr√∂√üen experimentell in K, G1, G2, G3 & G4. Daten wurden aber bis zu High School erhoben.\nDie Variable g4tmathss etwa erfasst die Mathematikleistung in Klasse 4, die Variablen g4pteffr und g4ptvalu den von Lehrkr√§ften eingesch√§tzte schulische Leistungsbereitschaft bzw. die Wertsch√§tzung schulischer Inhalte.\nWie gro√ü sch√§tzt ihr die Effekte der Pr√§diktoren g4pteffr und g4ptvalu ein? Berechnet die standardisierten und nicht-standardisierten Regressionsmodelle und diskutiert die interne, externe und Konstruktvalidit√§t der so erhaltenen Befunde.\n\n\n\nlibrary(haven)\nlibrary(sjPlot)\ndata_star_sampled &lt;- read_spss(\"data/data_star_sampled.sav\")\n\nmod02 &lt;- lm(g4tmathss ~ g4pteffr, data = data_star_sampled)\nmod03 &lt;- lm(g4tmathss ~ g4ptvalu, data = data_star_sampled)\n\ntab_model(mod02, mod03, show.std = T, show.ci = F)\n\n\n\n\ntab_model(mod02, mod03, show.std = T, show.ci = F)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†\nTOTAL MATH SCALE SCORE\nCTBS GRADE 4\nTOTAL MATH SCALE SCORE\nCTBS GRADE 4\n\n\nPredictors\nEstimates\nstd. Beta\np\nEstimates\nstd. Beta\np\n\n\n(Intercept)\n625.22\n-0.00\n&lt;0.001\n644.89\n-0.00\n&lt;0.001\n\n\nGRADE 4 PARTICIPATION\nSUBSCORE: EFFORT\n1.79\n0.41\n&lt;0.001\n\n\n\n\n\nGRADE 4 PARTICIPATION\nSUBSCORE: VALUE\n\n\n\n5.40\n0.26\n0.011\n\n\nObservations\n93\n93\n\n\nR2 / R2 adjusted\n0.169 / 0.160\n0.069 / 0.058\n\n\n\n\n\n\n\n\nDer standardisierte Regressionskoeffizient der Effort-Skala ist mit .58 enorm gro√ü ausgepr√§gt und auch der Effekt des Pr√§diktors value ist substantiell. Beachtet werden muss allerdings, dass die p-Werte nichts √ºber die Sicherheit der Unterschiedlichkeit der beiden Steigungsparameter aussagt. Getestet wurde jeweils wieder nur die Nullhypothese eines Nulleffekts. Zu kritisieren sind hier sicher interne und Konstruktvalidit√§t. Effort und Value der Sch√ºler:innen wurden von den Lehrkr√§ften ohne vorherige Raterschulung eingesch√§tzt. Daher ist anzunehmen, dass dieses Rating auch durch die Leistung der Sch√ºler:innen verzerrt ist (z.B. im Sinne eines Haloeffekts, Dennis 2007). Die interne Validit√§t der Schlussfolgerung aus diesen Regressionsmodellen ist schwach, da es sich nur um querschnittliche Daten handelt und die Auspr√§gung der unabh√§ngigen Variable nicht randomisiert wurde.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Einfache und Multiple lineare Regression</span>"
    ]
  },
  {
    "objectID": "regression.html#multiple-lineare-regression",
    "href": "regression.html#multiple-lineare-regression",
    "title": "2¬† Einfache und Multiple lineare Regression",
    "section": "2.3 Multiple lineare Regression",
    "text": "2.3 Multiple lineare Regression\nIn diesem Unterkapitel soll in die multiple Regression eingef√ºhrt werden. Dazu dient ebenfalls ein Erkl√§rvideo gefolgt von Aufgaben.\n\n2.3.1 Erkl√§rvideo\n\n\n\n\n\n\n\n2.3.2 Erkl√§rvideo\nDie standardisierten Steigungskoeffizeinten \\(\\beta_i\\) stellen ja eine Effektst√§rke der partiellen Assoziation des Pr√§diktors \\(i\\) mit der abh√§ngigen Variable dar. Nimmt man mehrere Pr√§diktoren auf, kann der Determinationskoeffizient \\(R^2\\) eine Effektst√§rke f√ºr die G√ºte des Gesamtmodells darstellen.\n\n\n\n\n\n\n\n2.3.3 Worked Out Example\nIn der √úbungsaufgabe zur einfachen linearen Regression haben wir vermutet, dass Einsch√§tzung von Effort und Value durch die Lehrkraft von der Leistung der Lernenden gef√§rbt sein k√∂nnte. W√§re dem so, sollte man ein Sinken der Pr√§diktionskraft des Pr√§diktors Value nach Adjustierung um die Vorjahresleistung beobachten.\n\ntab_model(\n    lm(g4tmathss ~ g4ptvalu, data = data_star_sampled),\n    lm(g4tmathss ~ g4ptvalu + g3tmathss, data = data_star_sampled),\n    show.ci = F, show.std = T\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†\nTOTAL MATH SCALE SCORE\nCTBS GRADE 4\nTOTAL MATH SCALE SCORE\nCTBS GRADE 4\n\n\nPredictors\nEstimates\nstd. Beta\np\nEstimates\nstd. Beta\np\n\n\n(Intercept)\n644.89\n-0.00\n&lt;0.001\n218.90\n0.00\n&lt;0.001\n\n\nGRADE 4 PARTICIPATION\nSUBSCORE: VALUE\n5.40\n0.26\n0.011\n2.89\n0.13\n0.084\n\n\nTOTAL MATH SCALE SCORE\nSAT GRADE 3\n\n\n\n0.73\n0.66\n&lt;0.001\n\n\nObservations\n93\n92\n\n\nR2 / R2 adjusted\n0.069 / 0.058\n0.494 / 0.483\n\n\n\n\n\n\n\n\nDies ist tats√§chlich der Fall. Der standardisierte Regressionskoeffizient sinkt von .35 auf .12.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Einfache und Multiple lineare Regression</span>"
    ]
  },
  {
    "objectID": "regression.html#aufgabe-2",
    "href": "regression.html#aufgabe-2",
    "title": "2¬† Einfache und Multiple lineare Regression",
    "section": "2.4 Aufgabe",
    "text": "2.4 Aufgabe\n\nAufgabeL√∂sungshinweiseL√∂sung\n\n\nUntersucht, inwiefern die ebenfalls Lehrer:inneingesch√§tzte Variable Initiative (z.B. ‚Äúparticipates actively in class discussions‚Äù) g4ptinit die Mathematikleistung in Klasse 4 g4tmathss pr√§diziert und inwiefern sich der Effekt nach Adjustierung der Vortestleistung g3tmathss √§ndert\n\n\n\nlm(g4tmathss ~ g4ptinit, data = data_star_sampled)\nlm(g4tmathss ~ g4ptinit + g3tmathss, data = data_star_sampled)\n\n\n\n\ntab_model(\n    lm(g4tmathss ~ g4ptinit, data = data_star_sampled),\n    lm(g4tmathss ~ g4ptinit + g3tmathss, data = data_star_sampled),\n    show.std = T, show.ci = F)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†\nTOTAL MATH SCALE SCORE\nCTBS GRADE 4\nTOTAL MATH SCALE SCORE\nCTBS GRADE 4\n\n\nPredictors\nEstimates\nstd. Beta\np\nEstimates\nstd. Beta\np\n\n\n(Intercept)\n651.74\n-0.00\n&lt;0.001\n244.84\n0.00\n&lt;0.001\n\n\nGRADE 4 PARTICIPATION\nSUBSCORE: INITIATIVE\n2.34\n0.37\n&lt;0.001\n1.10\n0.17\n0.031\n\n\nTOTAL MATH SCALE SCORE\nSAT GRADE 3\n\n\n\n0.70\n0.64\n&lt;0.001\n\n\nObservations\n93\n92\n\n\nR2 / R2 adjusted\n0.135 / 0.126\n0.504 / 0.493\n\n\n\n\n\n\n\n\nDer standardisierte Regressionskoeffizient der Initiative-Skala ist mit .49 gro√ü ausgepr√§gt. Nach Adjustierung um die Vorjahrestestleistung, sinkt die pr√§diktive Kraft deutlich, es ist aber weiterhin ein substantieller Effekt zu beobachten.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Einfache und Multiple lineare Regression</span>"
    ]
  },
  {
    "objectID": "regression.html#weiterf√ºhrende-literatur",
    "href": "regression.html#weiterf√ºhrende-literatur",
    "title": "2¬† Einfache und Multiple lineare Regression",
    "section": "2.5 Weiterf√ºhrende Literatur",
    "text": "2.5 Weiterf√ºhrende Literatur\n\n\n\n\n\n\nLiteraturempfehlungen zum Thema Regression\n\n\n\n\n\n\nEid, M., Gollwitzer, M., & Schmitt, M. (2013). Statistik und Forschungsmethoden: Lehrbuch. Mit Online-Materialien (3. Aufl.). Beltz.\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and Other Stories (1. Aufl.). Cambridge University Press. https://doi.org/10.1017/9781139161879\n\n\n\n\n\n\n\n\nAchilles, C. M., Helen Pate Bain, F. Bellot, J. Boyd-Zaharias, J. Finn, J. Folger, John Johnston, und Elizabeth Word. 1985. ‚ÄûThe State of Tennessee‚Äôs Student/Teacher Achievement Ratio (STAR) Project‚Äú. Technical {{Report}}. Tennessee State Department of Educatbn.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral Sciences. 2. Aufl. New Jersey: Lawrence Erlbaum.\n\n\nDennis, Ian. 2007. ‚ÄûHalo Effects in Grading Student Projects‚Äú. Journal of Applied Psychology 92 (4): 1169‚Äì76. https://doi.org/10.1037/0021-9010.92.4.1169.\n\n\nMoosbrugger, Helfried. 2011. Lineare Modelle: Regressions- und Varianzanalysen ; mit einem Anhang √ºber Matrixalgebra. 4., vollst√§ndig √ºberarbeitete und erg√§nzte Auflage. Psychologie Lehrtexte. Bern: Verlag Hans Huber.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Einfache und Multiple lineare Regression</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literatur",
    "section": "",
    "text": "Achilles, C. M., Helen Pate Bain, F. Bellot, J. Boyd-Zaharias, J. Finn,\nJ. Folger, John Johnston, and Elizabeth Word. 1985. ‚ÄúThe State of\nTennessee‚Äôs Student/Teacher Achievement Ratio\n(STAR) Project.‚Äù Technical {{Report}}.\nTennessee State Department of Educatbn.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral\nSciences. 2nd ed. New Jersey: Lawrence\nErlbaum.\n\n\nDennis, Ian. 2007. ‚ÄúHalo Effects in Grading Student\nProjects.‚Äù Journal of Applied Psychology 92 (4):\n1169‚Äì76. https://doi.org/10.1037/0021-9010.92.4.1169.\n\n\nMoosbrugger, Helfried. 2011. Lineare Modelle: Regressions- und\nVarianzanalysen ; mit einem Anhang √ºber\nMatrixalgebra. 4., vollst√§ndig\n√ºberarbeitete und erg√§nzte Auflage.\nPsychologie Lehrtexte. Bern: Verlag Hans\nHuber.",
    "crumbs": [
      "Literatur"
    ]
  },
  {
    "objectID": "regression_assumptions.html",
    "href": "regression_assumptions.html",
    "title": "3¬† Annahmen f√ºr die Inferenzstatistik (Regressionsdiagnostik)",
    "section": "",
    "text": "3.1 Parameter, Effektst√§rken und Inferenzstatistiken\nWir haben nun die Parametrisierung der multiplen linearen Regression kennengelernt und dazu die folgenden Parameter, Effektst√§rken und Inferenzstatistiken kennengelernt:",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Annahmen f√ºr die Inferenzstatistik (Regressionsdiagnostik)</span>"
    ]
  },
  {
    "objectID": "regression_assumptions.html#parameter-effektst√§rken-und-inferenzstatistiken",
    "href": "regression_assumptions.html#parameter-effektst√§rken-und-inferenzstatistiken",
    "title": "3¬† Annahmen f√ºr die Inferenzstatistik (Regressionsdiagnostik)",
    "section": "",
    "text": "Parameter:\n\nIntercept der Regression \\(b_0\\)\nSlope der Regression \\(b_1\\)\n\nEffektst√§rken:\n\nSlope der standardisierten Regression \\(\\beta_1\\)\nDeterminationskoeffizient \\(R^2\\)\n\nInferenzstatistiken:\n\n\\(p\\)-Werte f√ºr Parameter (Typische \\(H_0\\text{: }\\;b_i = 0\\))\n\\(p\\)-Werte f√ºr \\(R^2\\) (Typische \\(H_0\\text{: }\\;R^2 = 0\\) oder \\(H_0\\text{: }\\;R^2_{Modell_1} = R^2_{Modell_2}\\))\n\\(BF\\)-Werte f√ºr \\(R^2\\) (Typische \\(H_0\\text{: }\\;R^2 = 0\\) oder \\(H_0\\text{: }\\;R^2_{Modell_1} = R^2_{Modell_2}\\))\nKonfidenzintervalle f√ºr Parameter\nBayesian Credibility Intervalle f√ºr Parameter",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Annahmen f√ºr die Inferenzstatistik (Regressionsdiagnostik)</span>"
    ]
  },
  {
    "objectID": "regression_assumptions.html#annhamen",
    "href": "regression_assumptions.html#annhamen",
    "title": "3¬† Annahmen f√ºr die Inferenzstatistik (Regressionsdiagnostik)",
    "section": "3.2 Annhamen",
    "text": "3.2 Annhamen\nDie Verfahren zur Berechnung der Inferenzstatistiken treffen Annahmen √ºber den datengenerierenden Mechanismus. Sind diese verletzt, kann man die Inferenzstatistiken dennoch berechnen, sie sind aber nicht mehr aussagekr√§ftig - √§hnlich wie man auch in einem nicht rechtwinkligen Dreieck \\(a^2 + b^2\\) berechnen kann, diese Summe aber nicht \\(c^2\\) ergibt. So wie man also vor der Anwendung des Satz des Pythagoras \\(a^2 + b^2 = c^2\\) pr√ºfen muss, ob das Dreick rechtwinklig ist, muss man vor der Berechnung der Inferenzstatistiken deren Voraussetzungen pr√ºfen.\nZur Definition der Voraussetzungen von inferenzstatistischen Verfahren wird meist zun√§chst ein Populationsmodell spezifiziert um dann zus√§tzliche Annahmen f√ºr die Sch√§tzung anzugeben. Das Populationsmodell der multiplen linearen Regression lautet:\n\\[\n\\begin{aligned}\nY= & E\\left(Y \\mid X_1, \\ldots, X_k\\right)+\\varepsilon=\\beta_0+\\beta_1 \\cdot X_1+\\beta_2 \\cdot X_2 \\\\\n& +\\ldots+\\beta_j \\cdot X_j+\\ldots+\\beta_k \\cdot X_k+\\varepsilon\n\\end{aligned}\n\\] Dabei stellt \\(E\\left(Y \\mid X_1, \\ldots, X_k\\right)\\) den bedingten Erwartungswert von Y dar.\n\n\n\n\n\n\nWichtig\n\n\n\n\n\nF√ºr die Sch√§tzung der Parameter wird meist zus√§tzlich angenommen:\n\nHomoskedastizit√§t: \\(\\operatorname{Var}(Y \\mid X)=\\operatorname{Var}(\\varepsilon \\mid X)=\\sigma_{\\varepsilon}^2\\). Die Streuung der Residuen muss also f√ºr verschiedene Pr√§diktorwerte konstant sein.\nBedingte Normalverteilung: \\(\\varepsilon_i \\sim N\\left(\\mu_i, \\sigma_{i}^2\\right)\\). Die Residuen m√ºssen normalverteilt sein\nUnabh√§ngigkeit der Residuen: \\(\\varepsilon_i \\sim \\text{i.i.d.}\\). Die Residuen ¬ªd√ºrfen keine Information teilen¬´.\n\n\n\n\nDiese Annahmen sind nach dem Satz von Gau√ü Markov zu \\(\\forall i: \\varepsilon_i \\sim\\left(0, \\sigma^2\\right)\\) abschw√§chbar. Da dies aber weniger anschaulich ist bleiben wir bei den erstgenannten Annahmen.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Annahmen f√ºr die Inferenzstatistik (Regressionsdiagnostik)</span>"
    ]
  },
  {
    "objectID": "regression_assumptions.html#diagnostik-der-annahmen",
    "href": "regression_assumptions.html#diagnostik-der-annahmen",
    "title": "3¬† Annahmen f√ºr die Inferenzstatistik (Regressionsdiagnostik)",
    "section": "3.3 Diagnostik der Annahmen",
    "text": "3.3 Diagnostik der Annahmen\nWie diagnostiziert man aber nun inwiefern diese Annahmen f√ºr vorliegende Daten problematisch sind? Zun√§chst: Diese sog. Regressionsdiagnostik ist wesentlich komplexer und bedarf gr√∂√üerer Expertise als das Spezifizieren, Sch√§tzen und Interpretieren der Modelle - Hilfe und Kontrolle durch kompetente Forscher:innen ist also ratsam.\n\n3.3.1 Graphische und koeffizientenbasierte Diagnostik\nPrinzipiell unterscheidet man zwischen graphischer und koeffizientenbasierter Regressionsdiagnostik. Bei ersterer versucht man aus geeigneten Grafiken die Einhaltung/Abweichung der Annahmen abzusch√§tzen - bei zweiterer berechnet man Koeffizienten welche die Abweichung von den Annahmen beschreiben.\n\n3.3.1.1 Graphische Regressionsdiagnostik\nZun√§chst plottet man eigentlich immer die Rohdaten und das gesch√§tzte Modell.\n\nlibrary(haven)\nlibrary(tidyverse)\n\n# read the aggregated data\ndata_star_g3sampled &lt;- read_spss(\"data/data_star_sampled.sav\")\n\n# plot rawdata\nggplot(data_star_g3sampled,                       # the used data set\n       aes(g3classsize, g3tmathss)) +                # define x- and y-axis\n    geom_jitter() +                                  # add jittered points\n    geom_rug(position = position_jitter(), \n             alpha = .2) +                           # add rug at margins\n    stat_smooth(se = F, method = \"lm\") +             # add linear smoother\n    theme_minimal()                                  # make appearance \"clearer\"\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 41 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 41 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nDas Paket {performance} liefert zudem weitere sehr heuristische Plots f√ºr die Graphische Regressionsdiagnostik:\n\nlibrary(performance)\n\n# Spezifikation und Sch√§tzung des Modells\nmod00 &lt;- lm(g3tmathss ~ g3classsize, \n            data = data_star_g3sampled)\n\n# Grafische Regressionsdiagostik\ncheck_model(mod00)",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Annahmen f√ºr die Inferenzstatistik (Regressionsdiagnostik)</span>"
    ]
  },
  {
    "objectID": "regression_assumptions.html#annahmen",
    "href": "regression_assumptions.html#annahmen",
    "title": "3¬† Annahmen f√ºr die Inferenzstatistik (Regressionsdiagnostik)",
    "section": "3.2 Annahmen",
    "text": "3.2 Annahmen\nDie Verfahren zur Berechnung der Inferenzstatistiken treffen Annahmen √ºber den datengenerierenden Mechanismus. Sind diese verletzt, kann man die Inferenzstatistiken dennoch berechnen, sie sind aber nicht mehr aussagekr√§ftig - √§hnlich wie man auch in einem nicht rechtwinkligen Dreieck \\(a^2 + b^2\\) berechnen kann, diese Summe aber nicht \\(c^2\\) ergibt. So wie man also vor der Anwendung des Satz des Pythagoras \\(a^2 + b^2 = c^2\\) pr√ºfen muss, ob das Dreick rechtwinklig ist, muss man vor der Berechnung der Inferenzstatistiken deren Voraussetzungen pr√ºfen.\nZur Definition der Voraussetzungen von inferenzstatistischen Verfahren wird meist zun√§chst ein Populationsmodell spezifiziert um dann zus√§tzliche Annahmen f√ºr die Sch√§tzung anzugeben. Das Populationsmodell der multiplen linearen Regression lautet:\n\\[\n\\begin{aligned}\nY=\\;& E\\left(Y \\mid X_1, \\ldots, X_k\\right)+\\varepsilon=\\beta_0+\\beta_1 \\cdot X_1+\\beta_2 \\cdot X_2 \\\\\n& +\\ldots+\\beta_j \\cdot X_j+\\ldots+\\beta_k \\cdot X_k+\\varepsilon\n\\end{aligned}\n\\] Dabei stellt \\(E\\left(Y \\mid X_1, \\ldots, X_k\\right)\\) den bedingten Erwartungswert von Y dar.\n\n\n\n\n\n\nWichtig\n\n\n\n\n\nF√ºr die Sch√§tzung der Parameter wird meist zus√§tzlich angenommen:\n\nHomoskedastizit√§t: \\(\\operatorname{Var}(Y \\mid X)=\\operatorname{Var}(\\varepsilon \\mid X)=\\sigma_{\\varepsilon}^2\\). Die Streuung der Residuen muss also f√ºr verschiedene Pr√§diktorwerte konstant sein.\nBedingte Normalverteilung: \\(\\varepsilon_i \\sim N\\left(\\mu_i, \\sigma_{i}^2\\right)\\). Die Residuen m√ºssen normalverteilt sein\nUnabh√§ngigkeit der Residuen: \\(\\varepsilon_i \\sim \\text{i.i.d.}\\). Die Residuen ¬ªd√ºrfen keine Information teilen¬´.\n\n\n\n\nDiese Annahmen sind nach dem Satz von Gau√ü Markov zu \\(\\forall i: \\varepsilon_i \\sim\\left(0, \\sigma^2\\right)\\) abschw√§chbar. Da dies aber weniger anschaulich ist bleiben wir bei den erstgenannten Annahmen.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Annahmen f√ºr die Inferenzstatistik (Regressionsdiagnostik)</span>"
    ]
  },
  {
    "objectID": "regression_with_dummies.html",
    "href": "regression_with_dummies.html",
    "title": "4¬† Regression mit Dummyvariablen",
    "section": "",
    "text": "4.1 Erkl√§rvideo",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Regression mit Dummyvariablen</span>"
    ]
  },
  {
    "objectID": "regression_with_dummies.html#erkl√§rvideo",
    "href": "regression_with_dummies.html#erkl√§rvideo",
    "title": "4¬† Regression mit Dummyvariablen",
    "section": "",
    "text": "4.1.1 Worked out Example I (dichotomer Pr√§diktor)\nDer STAR-Datensatz enth√§lt die dichotome Variable g3size welche nur zwischen kleinen Klassen \"small\" und gro√üen Klassen bzw. gro√üen Klassen mit Hilfslehrkraft \"not_small\" unterscheidet. Tr√§gt man diese Variable gegen die Klassengr√∂√üe auf erh√§lt man den folgenden Plot:\n\ndata_star_g3sampled |&gt; \n  ggplot(aes(g3size, g3classsize)) +\n  geom_jitter() +\n  theme_minimal()\n\n\n\n\n\n\n\n\nIst man nun an einem Vergleich der Mathematikleistung in den gro√üen vs.¬†den kleinen Klassen interessiert, kann man die Variable g3size als Pr√§diktor verwenden. Ein deskriptiver Plot sieht wie folgt aus:\n\ndata_star_g3sampled |&gt; \n  ggplot(aes(g3size, g3tmathss)) + \n  geom_boxplot() +\n  geom_jitter() +\n  theme_minimal()\n\nWarning: Removed 41 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\nWarning: Removed 41 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nVerwendet man g3size als Pr√§diktor in lm() erstellt R automatisch die entsprechende Dummyvariable:\n\nmod04 &lt;- lm(g3tmathss ~ g3size, data = data_star_g3sampled)\nsummary(mod04)\n\n\nCall:\nlm(formula = g3tmathss ~ g3size, data = data_star_g3sampled)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-96.669 -25.645  -4.669  28.331 160.380 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  613.620      2.950 208.014   &lt;2e-16 ***\ng3sizesmall    9.049      4.550   1.989   0.0476 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 38.57 on 293 degrees of freedom\n  (41 observations deleted due to missingness)\nMultiple R-squared:  0.01332,   Adjusted R-squared:  0.009954 \nF-statistic: 3.956 on 1 and 293 DF,  p-value: 0.04764\n\n\nDieser Output ist in die folgende Regressionsgleichung √ºbersetzbar: \\[\n\\operatorname{\\widehat{g3tmathss}} = 614.52 + 12.09(\\operatorname{g3size}_{\\operatorname{small}})\n\\] Am Names des Pr√§diktors g3sizesmall kann man erkennen, dass die lm()-Funktion aus der Variable g3size eine Dummyvariable gemacht hat, die den Wert 0 hat, wenn g3size == \"not_small\" gilt (Referenzkategorie) und den Wert 1 hat, falls es sich um eine kleine Klasse handelt.\nAm Output erkennt man nun, dass die gro√üen Klassen im Durchschnitt 613.619883 Punkte erzielen und die die kleinen Klassen 9.0494718 Punkte mehr. Ist das nun ein gro√üer oder kleiner Unterschied? Diese Frage kann man auf mehrere Arten beantworten: Man kann z.B. das \\(R^2\\) betrachten oder man standardisiert (nur) die abh√§ngige Variable. Geplottet sieht das dann so aus:\n\ndata_star_g3sampled |&gt; \n  ggplot(aes(g3size, scale(g3tmathss))) + \n  geom_boxplot() +\n  geom_jitter() +\n  theme_minimal()\n\nWarning: Removed 41 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\nWarning: Removed 41 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nMan kann hier schon die Mittelwertsdifferenz in Standardabweichungen absch√§tzen, was ja dem Cohen‚Äôs d entspricht. Das entsprechende Regressionsmodell liefert dieses ebenfalls:\n\nmod05 &lt;- lm(scale(g3tmathss) ~ g3size, data = data_star_g3sampled)\nsummary(mod05)\n\n\nCall:\nlm(formula = scale(g3tmathss) ~ g3size, data = data_star_g3sampled)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.4935 -0.6615 -0.1204  0.7308  4.1369 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept) -0.09812    0.07609  -1.289   0.1982  \ng3sizesmall  0.23342    0.11736   1.989   0.0476 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.995 on 293 degrees of freedom\n  (41 observations deleted due to missingness)\nMultiple R-squared:  0.01332,   Adjusted R-squared:  0.009954 \nF-statistic: 3.956 on 1 and 293 DF,  p-value: 0.04764\n\n\nDie Mittelwertsdifferenz (der Slope) liegt also bei 0.2334241. Dieses Wert erh√§lt man auch wenn man Cohen‚Äôs d berechnet:\n\nlibrary(effectsize)\ncohens_d(g3tmathss ~ g3size, data = data_star_g3sampled)\n\nWarning: Missing values detected. NAs dropped.\n\n\nCohen's d |         95% CI\n--------------------------\n-0.23     | [-0.47,  0.00]\n\n- Estimated using pooled SD.\n\n\nManchmal ergeben sich bei dieser Berechnung kleinste Unterschiede, je nach dem wie die Standardabweichungen der beiden Gruppen gemittelt (gepoolt) werden.\n\n\n4.1.2 Worked out Example I (trichotomer Pr√§diktor)\nM√∂chte man die drei verschiedenen Gruppen des STAR-Experimentes miteinander vergleichen, setzt man in die lm() Funktion die trichotome Variable g3classtype als Pr√§diktor ein.\n\nmod06 &lt;- lm(g3tmathss ~ g3classtype, data = data_star_g3sampled)\nsummary(mod06)\n\n\nCall:\nlm(formula = g3tmathss ~ g3classtype, data = data_star_g3sampled)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-96.669 -25.882  -4.669  27.905 159.905 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 614.0946     4.4918 136.716   &lt;2e-16 ***\ng3classtyperegular_with_aid  -0.8369     5.9639  -0.140    0.889    \ng3classtypesmall              8.5748     5.6760   1.511    0.132    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 38.64 on 292 degrees of freedom\n  (41 observations deleted due to missingness)\nMultiple R-squared:  0.01339,   Adjusted R-squared:  0.00663 \nF-statistic: 1.981 on 2 and 292 DF,  p-value: 0.1398\n\n\nMan erh√§lt nun im Output zwei Pr√§diktoren, da die trichotome Variable zu einer Referenzkategrie und zwei Dummyvariablen f√ºr die zwei Unterschiede der anderen beiden Gruppen zu dieser Referenzkategorie umkodiert wurde. Demnach ist also der Mittelwert in der Referenzkategorie (regular class) gleich dem Intercept 614.0945946, der Mittelwert in den kleinen Klassen unterscheidet sich um 8.5747602 und der in Klassen mit Hilfslehrkraft um -0.8368626.\nUm bei der Interpretation keine Fehler zu machen lohnt es sich immer die Mittelwerte nochmals klassisch gegenzurechnen:\n\ndata_star_g3sampled |&gt; \n  group_by(g3classtype) |&gt; \n  summarize(MWg3tmathss = mean(g3tmathss, na.rm = T))\n\n# A tibble: 3 √ó 2\n  g3classtype      MWg3tmathss\n  &lt;chr&gt;                  &lt;dbl&gt;\n1 regular                 614.\n2 regular_with_aid        613.\n3 small                   623.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Regression mit Dummyvariablen</span>"
    ]
  },
  {
    "objectID": "√úbung_Sitzung_Regression_II.html",
    "href": "√úbung_Sitzung_Regression_II.html",
    "title": "5¬† √úbungen zur einfachen, multiplen und Dummyregession",
    "section": "",
    "text": "5.1 Import der Daten\nDatengrundlagen soll weiterhin die STAR-Studie sein, wobei wir wieder ein Subset der Daten verwenden das jeweils nur eine:n Sch√ºler:in pro Klasse enth√§lt, um Abh√§ngigkeiten der Residuen zu vermeiden (Datensatz).\nlibrary(tinytable)   # f√ºr sch√∂ne Tabellen\nlibrary(BayesFactor) # f√ºr BFs\nlibrary(ggdag)       # f√ºr Kausaldiagramme\nlibrary(dagitty)     # f√ºr Kausale Relationierungen\nlibrary(ggforce)     # f√ºr Sinaplots\nlibrary(haven)       # f√ºr den Import\nlibrary(sjPlot)      # f√ºr die Regressionstabellen\nlibrary(performance) # f√ºr die Plots zur Regressionsidagnostik\nlibrary(tidyverse)   # f√ºr das Data Wrangling und Plotting\n\n# Import der Daten\ndata_star_g3sampled &lt;- read_spss(\"data/data_star_sampled.sav\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>√úbungen zur einfachen, multiplen und Dummyregession</span>"
    ]
  },
  {
    "objectID": "√úbung_Sitzung_Regression_II.html#√ºbung-1-versetzungsempfehlung",
    "href": "√úbung_Sitzung_Regression_II.html#√ºbung-1-versetzungsempfehlung",
    "title": "5¬† √úbungen zur einfachen, multiplen und Dummyregession",
    "section": "5.2 √úbung 1: Versetzungsempfehlung",
    "text": "5.2 √úbung 1: Versetzungsempfehlung\n\nAufgabeL√∂sungshinweis IL√∂sungshinweis IIL√∂sungshinweis IIIRegressionsdiagnostik\n\n\nIn dieser Aufgabe wollen wir uns anschauen ob und wenn ja wie viel sich Drittkl√§ssler mit und ohne Versetzungsempfehlung in der Mathematikleistung g3tmathss von einander unterscheiden. Die Versetzungsempfehlung steckt in der Variable g3promote und hat die folgenden Auspr√§gungen und Belegungen:\n\ndata_star_g3sampled |&gt; \n  # split dataset according to the value of g3promote\n  group_by(g3promote) |&gt; \n  # summarize each data set separately and combine the results\n  summarize(count = n(),\n            mean_per_g3promote = mean(g3tmathss, na.rm = T))\n\n# A tibble: 3 √ó 3\n  g3promote                          count mean_per_g3promote\n  &lt;dbl+lbl&gt;                          &lt;int&gt;              &lt;dbl&gt;\n1  1 [YES, PROMOTION RECOMMENDED]      305               622.\n2  2 [NO, PROMOTION NOT RECOMMENDED]    12               582.\n3 NA                                    19               634.\n\n\n\n\n\n\n\n\nWarnung\n\n\n\n\n\nAchtung am Output &lt;dbl+lbl&gt; kann man erkennen dass die nominale Variable der Versetzung als metrische Variable kodiert ist!\n\n\n\n\n\nDa die Variable nur zwei Auspr√§gungen hat, kann man sie als Dummypr√§diktor verwenden. Ein entsprechender Plot sieht wie folgt aus:\n\ndata_star_g3sampled |&gt; \n  ggplot(aes(as.factor(g3promote), g3tmathss)) +\n  geom_boxplot() +\n  geom_jitter() + \n  theme_minimal()\n\nWarning: Removed 30 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\nWarning: Removed 30 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n\n# unstandardisiertes Modell\nmod07 &lt;- lm(g3tmathss ~ as.factor(g3promote), data = data_star_g3sampled)\n\n# Print des standardisierten und unstandardisierten Modells\ntab_model(mod07, show.std = T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†\nTOTAL MATH SCALE SCORE\nSAT GRADE 3\n\n\nPredictors\nEstimates\nstd. Beta\nCI\nstandardized CI\np\n\n\n(Intercept)\n621.73\n0.04\n617.29¬†‚Äì¬†626.17\n-0.08¬†‚Äì¬†0.15\n&lt;0.001\n\n\nas.factor(g3promote)2\n-39.46\n-1.02\n-62.48¬†‚Äì¬†-16.43\n-1.61¬†‚Äì¬†-0.42\n0.001\n\n\nObservations\n296\n\n\nR2 / R2 adjusted\n0.037 / 0.034\n\n\n\n\n\n\n\n\n\n\nDer standardisierte Mittelwertsunterschied ist mit \\(\\beta_1 &gt;&gt; .7\\) klar ein gro√üer Effekt. Trotz der geringen Anzahl an Datenpunkten f√§llt dieser zudem signifikant aus.\n\n\nUm die Einhaltung der Voraussetzungen zu diagnostizieren helfen die folgenden grafischen Darstellungen.\n\ncheck_model(mod07)\n\n\n\n\n\n\n\n\nPosterior Predictive Checks, Linearit√§t & einflussreiche Datenpunkte scheinen unauff√§llig zu sein. Die Varianzhomogenit√§t ist auf den ersten Blick aufgrund der unterschiedlich vielen Datenpunkte schwer zu beurteilen. Berechnet man aber die Varianz je Gruppe\n\ndata_star_g3sampled |&gt; \n  # split dataset according to the value of g3promote\n  group_by(g3promote) |&gt; \n  # compute sd for each data set separately \n  summarize(sd_per_g3promote = sd(g3tmathss, na.rm = T))\n\n# A tibble: 3 √ó 2\n  g3promote                          sd_per_g3promote\n  &lt;dbl+lbl&gt;                                     &lt;dbl&gt;\n1  1 [YES, PROMOTION RECOMMENDED]                38.6\n2  2 [NO, PROMOTION NOT RECOMMENDED]             19.2\n3 NA                                             64.4\n\n\nstellt man nur eine Abweichung von weniger als 10% fest.\nDie Residuen scheinen allerdings f√ºr die gro√üen Werte schon substantiell von der Normalverteilung abzuweichen. Da die Stichprobengr√∂√üe in einer Gruppe zudem eher klein ist w√ºrde ich den p-Wert mit Vorsicht genie√üen. Typische alternative Modellierungen sind z.B. in (Pek, Wong, und Wong 2018) zu finden. Sehr einfach ist es z.B. die signed_rank() der AV zu berechnen, was typischerweise ab \\(N &gt; 11\\) robust ist [@].\n\nsigned_rank = function(x) sign (x) * rank (abs (x))\nmod08 &lt;- lm(signed_rank(g3tmathss) ~ as.factor(g3promote), data = data_star_g3sampled)\nsummary(mod08)\n\n\nCall:\nlm(formula = signed_rank(g3tmathss) ~ as.factor(g3promote), data = data_star_g3sampled)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-155.677  -70.677    0.823   74.823  148.823 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            156.677      5.085  30.813  &lt; 2e-16 ***\nas.factor(g3promote)2  -97.904     26.377  -3.712 0.000246 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 85.84 on 294 degrees of freedom\n  (40 observations deleted due to missingness)\nMultiple R-squared:  0.04476,   Adjusted R-squared:  0.04151 \nF-statistic: 13.78 on 1 and 294 DF,  p-value: 0.0002462\n\n\nAuch hier ist der (unstandardisierte und transformierte, daher nicht gut interpretierbare Unterschied) signifikant.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>√úbungen zur einfachen, multiplen und Dummyregession</span>"
    ]
  },
  {
    "objectID": "√úbung_Sitzung_Regression_II.html#√ºbung-2",
    "href": "√úbung_Sitzung_Regression_II.html#√ºbung-2",
    "title": "5¬† √úbungen zur einfachen, multiplen und Dummyregession",
    "section": "5.3 √úbung 2",
    "text": "5.3 √úbung 2\n\nAufgabeL√∂sung FF 1L√∂sung FF2L√∂sung FF3\n\n\nAngenommen eine Forscherin interessiert sich f√ºr das Zusammenspiel von sozio√∂konomischem Status und dem Effekt der Klassengr√∂√üe. Der STAR-Datensatz enth√§lt dichotome Variablen, die ‚Äúfree or reduced lunch‚Äù indizieren. Damit k√∂nnen wir folgende Forschungsfragen beantworten:\n\nGibt eine soziale Disparit√§t in der Mathematikleistung?\nWie f√§llt diese Disparit√§t nach Adjustierung um die Vorjahrestestleistung aus?\nUnterscheiden sich diese Disparit√§ten in kleinen/gro√üen Klassen (Moderatoreffekt)?\n\n\n\nUm die soziale Disparit√§t mit dem Dummypr√§diktor zu modellieren, k√∂nnen wir zun√§chst ein unstandardisiertes Modell spezifizieren, nachdem wir uns die Rohdaten angeschaut haben\n\n# look at the raw data\nggplot(data_star_g3sampled,\n       aes(g3freelunch, g3tmathss, group = g3freelunch)) +\n  geom_violin() +\n  geom_sina() +\n  stat_summary(fun.data =\"mean_sdl\", \n               fun.args = list(mult = 1),\n               color = \"#8cd000\") +\n  theme_minimal()\n\nWarning: Removed 39 rows containing non-finite outside the scale range\n(`stat_ydensity()`).\n\n\nWarning: Removed 39 rows containing non-finite outside the scale range\n(`stat_sina()`).\n\n\nWarning: Removed 39 rows containing non-finite outside the scale range\n(`stat_summary()`).\n\n\n\n\n\n\n\n\n# fit a unstandardized model\nmod09 &lt;- lm(g3tmathss ~ g3freelunch, data = data_star_g3sampled)\nsummary(mod09)\n\n\nCall:\nlm(formula = g3tmathss ~ g3freelunch, data = data_star_g3sampled)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-98.611 -25.611  -0.611  25.389 141.430 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  591.530      7.153  82.691  &lt; 2e-16 ***\ng3freelunch   19.041      4.406   4.322 2.12e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 37.81 on 295 degrees of freedom\n  (39 observations deleted due to missingness)\nMultiple R-squared:  0.05955,   Adjusted R-squared:  0.05636 \nF-statistic: 18.68 on 1 and 295 DF,  p-value: 2.118e-05\n\n\nDas \\(R^2\\) deutet bereits auf einen substantiellen Effekt hin, welchen man nach Standardisierung der y-Achse auch im Slope (\\(\\approx \\text{Cohen's d}\\)) sehen kann.\n\nmod10 &lt;- lm(scale(g3tmathss) ~ g3freelunch, data = data_star_g3sampled)\nsummary(mod10)\n\n\nCall:\nlm(formula = scale(g3tmathss) ~ g3freelunch, data = data_star_g3sampled)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.4806 -0.6443 -0.0154  0.6387  3.5578 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -0.7345     0.1800  -4.082 5.76e-05 ***\ng3freelunch   0.4790     0.1108   4.322 2.12e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.951 on 295 degrees of freedom\n  (39 observations deleted due to missingness)\nMultiple R-squared:  0.05955,   Adjusted R-squared:  0.05636 \nF-statistic: 18.68 on 1 and 295 DF,  p-value: 2.118e-05\n\n\nIn der Diagnostik sind die Posterior Predictives OK, gleichzeitig die Normalit√§t der Residuen in den Randbereichen deutlich verletzt\n\ncheck_model(mod09)\n\n\n\n\n\n\n\n\nAngesichts der Stichprobengr√∂√üe sollte das aufgrund des zentralen Grenzwertsatzes unproblematisch sein.\n\n\n\nmod11 &lt;- lm(g3tmathss ~ g3freelunch + g2tmathss, data = data_star_g3sampled)\ntab_model(mod09, mod11, show.std = T, show.ci = F)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†\nTOTAL MATH SCALE SCORE\nSAT GRADE 3\nTOTAL MATH SCALE SCORE\nSAT GRADE 3\n\n\nPredictors\nEstimates\nstd. Beta\np\nEstimates\nstd. Beta\np\n\n\n(Intercept)\n591.53\n-0.00\n&lt;0.001\n209.47\n0.00\n&lt;0.001\n\n\nFREE/REDUCED LUNCH STATUS\nGRADE 3\n19.04\n0.24\n&lt;0.001\n6.38\n0.08\n0.101\n\n\nTOTAL MATH SCALE SCORE\nSAT GRADE 2\n\n\n\n0.69\n0.68\n&lt;0.001\n\n\nObservations\n297\n219\n\n\nR2 / R2 adjusted\n0.060 / 0.056\n0.495 / 0.490\n\n\n\n\n\n\n\n\nDer nicht-signifikante p-Wert in mod11 ist als inkonklusiv zu interpretieren - es ist unklar ob Evidenz f√ºr die Abwesenheit eines Effekts vorliegt oder die Power/Stichprobe nicht gro√ü genug f√ºr Detektion eines Effekts. Klar ist jedoch, dass g3freelunch und g2tmathss deutlich korrelieren m√ºssen.\nEin Bayes Faktor der im Prinzip zwischen Evidence of Absence und Absence of Evidence unterscheiden kann ist auch inkonklusiv:\n\n# Bayes Factor for mod09 vs. mod11\nlmBF(g3tmathss ~ g3freelunch + g2tmathss, \n     data = data_star_g3sampled |&gt; select(g3tmathss, g2tmathss, g3freelunch) |&gt; na.omit()) /\n  lmBF(g3tmathss ~ g2tmathss, \n     data = data_star_g3sampled |&gt; select(g3tmathss, g2tmathss, g3freelunch) |&gt; na.omit())\n\nWarning: data coerced from tibble to data frame\nWarning: data coerced from tibble to data frame\n\n\nBayes factor analysis\n--------------\n[1] g3freelunch + g2tmathss : 0.3116583 ¬±0.01%\n\nAgainst denominator:\n  g3tmathss ~ g2tmathss \n---\nBayes factor type: BFlinearModel, JZS\n\n\n\n\n\n\n\n\nEure Interpretation?\n\n\n\n\n\nWie interpretiert ihr die Ergebnisse? Welche kausale Relationierung von\n\nl2 (learning behavior in Jahr 2)\nl3 (learning behavior in Jahr 3)\na2 (achievement in Jahr 2)\na2 (achievement in Jahr 2)\nfl (free lunch)\n\nhaltet ihr theoretisch f√ºr plausible und im Einklang mit den Daten? Im folgende ein Beispiel zur Inspiration\n\n# Denkbare kausale Relationierung\ndag &lt;- dagitty(\"dag {\n    l2 &lt;- fl -&gt; l3\n    l2 -&gt; a2\n    a2 -&gt; l3 -&gt; a3\n    l2 -&gt; l3\n    fl [exposure]\n    a3 [outcome]\n    l2 [unobserved]\n    l3 [unobserved]\n  }\")\n\ntidy_ggdag &lt;- tidy_dagitty(dag)\n\nggdag(tidy_ggdag) +\n  theme_dag()\n\n\n\n\n\n\n\n\n\n\n\n\n\nF√ºr eine Antwort auf FF3 k√∂nnte man neue Dummyvariablen anlegen, die indizieren ob f√ºr eine Sch√ºler:in\n\nfreelunch & kleine Klasse\nfreelunch & gro√üe Klasse\nkein freelunch & gro√üe Klasse\n\ngilt. kein freelunch & kleine Klasse wird dann zur Referenzkategorie.\n\ndata_ff3 &lt;- data_star_g3sampled |&gt; \n  mutate(freeL_smallCl = ifelse(g3freelunch == 1 & g3size == \"small\", 1, 0),\n         freeL_notsmallCl = ifelse(g3freelunch == 1 & g3size != \"small\", 1, 0),\n         notfreeL_notsmallCl = ifelse(g3freelunch != 1 & g3size != \"small\", 1, 0))\n\n# check recoding\ndata_ff3 |&gt;\n  select(g3freelunch, g3size, freeL_smallCl, freeL_notsmallCl, \n         notfreeL_notsmallCl) |&gt; \n  distinct() |&gt; \n  tt()\n\n \n\n  \n    \n    \n    tinytable_du6jskkdegqardvayz8w\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                g3freelunch\n                g3size\n                freeL_smallCl\n                freeL_notsmallCl\n                notfreeL_notsmallCl\n              \n        \n        \n        \n                \n                   2\n                  not_small\n                   0\n                   0\n                   1\n                \n                \n                   1\n                  not_small\n                   0\n                   1\n                   0\n                \n                \n                   2\n                  small    \n                   0\n                   0\n                   0\n                \n                \n                  NA\n                  small    \n                  NA\n                   0\n                   0\n                \n                \n                   1\n                  small    \n                   1\n                   0\n                   0\n                \n                \n                  NA\n                  not_small\n                   0\n                  NA\n                  NA\n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\nFittet man nun ein Modell mit diesen Pr√§diktoren ergibt sich folgendes Bild:\n\nmod12 &lt;- lm(g3tmathss ~ freeL_smallCl + freeL_notsmallCl + notfreeL_notsmallCl,\n            data = data_ff3)\ntab_model(mod12, show.std = T, show.ci = F)\n\n\n\n\n\n\n\n\n\n\n\n¬†\nTOTAL MATH SCALE SCORE\nSAT GRADE 3\n\n\nPredictors\nEstimates\nstd. Beta\np\n\n\n(Intercept)\n636.08\n-0.00\n&lt;0.001\n\n\nfreeL smallCl\n-21.65\n-0.22\n0.002\n\n\nfreeL notsmallCl\n-28.32\n-0.32\n&lt;0.001\n\n\nnotfreeL notsmallCl\n-10.91\n-0.13\n0.071\n\n\nObservations\n297\n\n\nR2 / R2 adjusted\n0.073 / 0.064\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEure Interpretation?\n\n\n\n\n\nWie interpretiert ihr die Ergebnisse?\n\n\n\n\n\n\n\n\n\n\nPek, Jolynn, Octavia Wong, und Augustine C. M. Wong. 2018. ‚ÄûHow to Address Non-Normality: A Taxonomy of Approaches, Reviewed, and Illustrated‚Äú. Frontiers in Psychology 9 (November). https://doi.org/10.3389/fpsyg.2018.02104.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>√úbungen zur einfachen, multiplen und Dummyregession</span>"
    ]
  }
]