# Einfache und Multiple lineare Regression
Die Modellierung mit dem allgemeinen linearen Modell (GLM) stellt eine sehr mächtige und elegante Möglichkeit zur Analyse von Daten dar [@moosbrugger2011]. Denn das GLM stellt eine Verallgemeinerung verbreiteter "einfacherer" Verfahren wie t-Tests, ANOVAs, ANCOVAs etc. dar. 
Ohne Grundkenntnisse der linearen Algebra und Wahrscheinlichkeitstheorie ist das GLM als Ganzes jedoch schwierig zu durchdringen. Daher beginnen wir mit zwei klassischen Spezialfällen des GLM, der einfachen linearen regression und der multiple linearen Regression. 

## Einfache lineare Regression
In diesem Unterkapitel soll in die einfache lineare Regression eingeführt werden. Dazu dient ein Erklärvideo gefolgt von Aufgaben.

### Erklärvideo
<div style="padding:56.25% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/910768759?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" style="position:absolute;top:0;left:0;width:100%;height:100%;" title="Erklaervideo_Zusammenhang_zweier_metrischer_Variablen"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>


:::{.callout-note collapse=false appearance='default' icon=false}
## Datengrundlage
Wir werden in diesen Workshop mit den Scientific Usefiles des STAR-Projektes [@achilles1985] arbeiten. Im STAR-Projekt standen die folgenden Forschungsfragen im Vordergrund:

1) What are the effects of a reduced class size on the achievement (normed and criterion tests) and development (self-concept, attendance, etc.) of students in public elementary school grades (K-3)?
2) Is there a cumulative effects of being in a small class over an extended time (4 years) as compared with a one-year effect for students in a small class for one year?
3) Does a training program designed to help teachers take maximum advantage of small classes, or to use aides effectively, improve student performance as compared with teachers who have no special preparation for their altered conditions?

Die entsprechenden Variablenbezeichnungen sowie die Kodierung der Variablenausprägungen werden in den jeweiligen Beispielen beschrieben.
:::


```{r}
#| echo: false
#| results: hide
#| warning: false

library(haven)
library(tidyverse)
```


```{r}
#| echo: false
#| results: hide
#| cache: true
# Read Complete Data
data_star <- read_spss("data/STAR_Students.sav")

# Select Variables
data_star_selected_variables <- 
    data_star |> 
    select(g4ptattn, g4ptmtrl, g4ptpers, g4ptlate, g4ptextr, g4ptdisc, 
           g4ptdiss, g4ptattn, g4ptmtrl, g4ptpers, g4ptlate, g4ptextr, 
           g4ptdisc, g4ptdiss, g8peattn, g8pmattn, g8pemtrl, g8pmmtrl, g8pepers, 
           g8pmpers, g8pelate, g8pmlate, g8pemore, g8pmmore, g8pedisc, g8pmdisc, 
           g8pediss, g8pmdiss,
           g4schid, g4tmathss, g4readcomprehss,
           g2classtype, g2tmathss, g2readbsraw, g2tchid, g2tyears,
           g2ttrain, g3ttrain, g4ptvalu, g4ptinit,
           g2surban, g3surban,
           g3classtype, g3tmathss, g3readbsraw, g3tchid, g3tyears, 
           g2selfconcraw, g3selfconcraw, g3classsize, g2classsize,
           g4pteffr, g4ptinit, g3motivraw, g2motivraw,
           g4tmathss, g4treadss, g3treadss, g2treadss,
           g1promote, g2promote, g3promote,
           g1freelunch, g2freelunch, g3freelunch) |> 
    mutate(g4ptattn = as.numeric(as.factor(g4ptattn)),
           g4ptmtrl = 6 - as.numeric(as.factor(g4ptmtrl)),
           g4ptpers = as.numeric(as.factor(g4ptpers)),
           g4ptlate = 6 - as.numeric(as.factor(g4ptlate)),
           
           g8peattn = as.numeric(as.factor(g8peattn)),
           g8pemtrl = 6 - as.numeric(as.factor(g8pemtrl)),
           g8pepers = as.numeric(as.factor(g8pepers)),
           g8pelate = 6 - as.numeric(as.factor(g8pelate)),
           
           g8pmattn = as.numeric(as.factor(g8pmattn)),
           g8pmmtrl = 6 - as.numeric(as.factor(g8pmmtrl)),
           g8pmpers = as.numeric(as.factor(g8pmpers)),
           g8pmlate = 6 - as.numeric(as.factor(g8pmlate)),
           
           g4ptmore = as.numeric(as.factor(g4ptextr)),
           g4ptdisc = as.numeric(as.factor(g4ptdisc)),
           g4ptdiss = as.numeric(as.factor(g4ptdiss)),
           
           g8pemore = as.numeric(as.factor(g8pemore)),
           g8pedisc = as.numeric(as.factor(g8pedisc)),
           g8pediss = as.numeric(as.factor(g8pediss)),
           
           g8pmmore = as.numeric(as.factor(g8pmmore)),
           g8pmdisc = as.numeric(as.factor(g8pmdisc)),
           g8pmdiss = as.numeric(as.factor(g8pmdiss)),
           )|> 
    rowwise() |> 
    mutate(g4effort = mean(c_across(c(g4ptattn, g4ptmtrl, g4ptpers, g4ptlate)), 
                           na.rm = T),
           g8efforte = mean(c_across(c(g8peattn, g8pemtrl, g8pepers, g8pelate)), 
                           na.rm = T),
           g8effortm = mean(c_across(c(g8pmattn, g8pmmtrl, g8pmpers, g8pmlate)), 
                           na.rm = T)) |> 
    ungroup()

write_sav(data_star_selected_variables, "data/data_star_selected_variables.sav")    

# select student per class according g3
data_star_sampled <- 
    data_star_selected_variables |> 
    group_by(g3tchid) |> 
    sample_n(1) |> 
    mutate(g3classtype = case_when(g3classtype == 1 ~ "small",
                                   g3classtype == 2 ~ "regular",
                                   g3classtype == 3 ~ "regular_with_aid",
                                   T ~ NA),
           g3size = ifelse(g3classtype == "small", "small", "not_small")) |> 
           filter(!is.na(g3classtype))

write_sav(data_star_sampled, "data/data_star_sampled.sav")
```

### Worked Out Example
Im ersten Worked Out Example wollen wir der Frage nachgehen, inwiefern die tatsächliche Klassengröße mit der Leistung in einem standardisierten Mathematiktest assoziiert ist.

#### Plot
In einem ersten Schritt (der ganz generell immer zu empfehlen ist) plotten wir die Rohdaten. Um keine Probleme mit geclusterten Daten zu bekommen, verwenden wir aus jeder Klasse nur eine:n zufällig gezogenen Schüler:in. 
Ein `.sav`-file, das die notwendigen Variablen enthält, kann `r xfun::embed_file("data/data_star_sampled.sav", "data_star_sampled.sav", "hier")` heruntergeladen werden.

```{r}
library(sjPlot)
library(bayestestR)

# read the aggregated data
data_star_g3sampled <- read_spss("data/data_star_sampled.sav")

# plot rawdata
ggplot(data_star_g3sampled,                       # the used data set
       aes(g3classsize, g3tmathss)) +                # define x- and y-axis
    geom_jitter() +                                  # add jittered points
    geom_rug(position = position_jitter(), 
             alpha = .2) +                           # add rug at margins
    stat_smooth(method = "linear", se = F) +                 # add linear smoother
    theme_minimal()                                  # make appearance "clearer"
```

#### Nicht-Standardisierte Regression
Um nun eine einfache lineare Regression zu schätzen, verwendet man in R die `lm()` Syntax. Links der Tilde `~` steht die abhängige Variable, rechts davon die unabhängige.

```{r}
mod00 <- lm(g3tmathss ~ g3classsize, 
            data = data_star_g3sampled)
```

Eine Übersicht über das Modell bekommt man, wenn man das Objekt `mod00` der der Funktion `summary()` übergibt.

```{r}
summary(mod00)
```

Die (lineare) Funktionsgleichung kann man sich mit der Funktion `extract_eq()` aus dem Paket `equatiomatic` ausgeben lassen. Mit der Option `use_coefs = T` setzt man die geschätzten Werte für die Parameter ein.

```{r}
library(equatiomatic)
extract_eq(mod00)
extract_eq(mod00, use_coefs = T)
```

Der Steigungskoeffizient beträgt $\approx .90$. Unterscheiden sich zwei Klassen um eine:n Schüler:in schätzt das Modell die Differenz im Mathematikscore auf $-.90$. Das Intercept wird auf $638.9$ geschätzt. Eine (hypothetische) Klasse mit 0 Schüler:innen hätte also einen durchschnittlichen Mathematikleistungsscore von $638.9$.  
Die drei Sternchen am rechten Rand des `summary()` Outputs zeigen an, dass die p-Werte für die Punktnullhypothesen 
$$
H_0\text{: Intercept} = 0
$$
$$
H_0\text{: Slope} = 0
$$
signifikant sind. Es macht also Sinn diese zu verwerfen.


#### Standardisierte Regression
Eine standardisierte lineare Regression setzt wie im Video erklärt voraus, dass alle Variablen z-standardisiert sind. Liegen unvollständige Daten vor, ist es wichtig diese Standardisierung erst **nach dem fallweisen Ausschluss** dieser fehlenden Daten vorzunehmen.

```{r}
mod01 <- lm(scale(g3tmathss) ~ scale(g3classsize), 
            data = data_star_g3sampled |> 
                # filter rows if g3tmathss or g3classsize is NA
                filter(!(is.na(g3tmathss) | is.na(g3classsize))))
summary(mod01)
extract_eq(mod01, use_coefs = T)
```

Das Intercept wird auf einen Wert mit 14 Nullen nach dem Komma geschätzt, ist also erwartungskonform quasi gleich null und nicht-signifikant. Der Steigungskoeffizient beträgt $\approx .20$ und liegt nach den Cohen Benchmarks [@cohen1988] im Bereich kleiner bis moderater Effekte.

Es gibt Pakete, die darauf spezialisiert sind (mehrere) Regressionsmodelle zusammengefasst übersichtlich in Tabellen darzustellen. Mit der folgenden Syntax bekommt man etwa nicht nur standardisierte und unstandardisierte Koeffizienten, sondern auch deren Konfidenzintervalle, beides auf eine sinnvolle Nachkommestellenanzahl gerundet:
```{r}
library(sjPlot)
tab_model(mod00, show.ci = .95, show.std = T)
```

## Aufgabe
::: {.panel-tabset}

### Aufgabe
Das STAR-Experiment variierte die Klassengrößen experimentell in K, G1, G2, G3 & G4. Daten wurden aber bis zu High School erhoben.  
Die Variable `g4tmathss` etwa erfasst die Mathematikleistung in Klasse 4, die Variablen `g4pteffr` und `g4ptvalu` den von Lehrkräften eingeschätzte schulische Leistungsbereitschaft bzw. die Wertschätzung schulischer Inhalte.

Wie groß schätzt ihr die Effekte der Prädiktoren `g4pteffr` und `g4ptvalu` ein? Berechnet die standardisierten und nicht-standardisierten Regressionsmodelle und diskutiert die interne, externe und Konstruktvalidität der so erhaltenen Befunde.


### Lösungshinweise
```{r}
#| results: hide

library(haven)
library(sjPlot)
data_star_sampled <- read_spss("data/data_star_sampled.sav")

mod02 <- lm(g4tmathss ~ g4pteffr, data = data_star_sampled)
mod03 <- lm(g4tmathss ~ g4ptvalu, data = data_star_sampled)

tab_model(mod02, mod03, show.std = T, show.ci = F)
```


### Lösung
```{r}
tab_model(mod02, mod03, show.std = T, show.ci = F)
```

Der standardisierte Regressionskoeffizient der Effort-Skala ist mit .58 enorm groß ausgeprägt und auch der Effekt des Prädiktors value ist substantiell. Beachtet werden muss allerdings, dass die p-Werte nichts über die Sicherheit der Unterschiedlichkeit der beiden Steigungsparameter aussagt. Getestet wurde jeweils wieder nur die Nullhypothese eines Nulleffekts.
Zu kritisieren sind hier sicher interne und Konstruktvalidität. Effort und Value der Schüler:innen wurden von den Lehrkräften ohne vorherige Raterschulung eingeschätzt. Daher ist anzunehmen, dass dieses Rating auch durch die Leistung der Schüler:innen verzerrt ist [z.B. im Sinne eines Haloeffekts, @dennis2007]. Die interne Validität der Schlussfolgerung aus diesen Regressionsmodellen ist schwach, da es sich nur um querschnittliche Daten handelt und die Ausprägung der unabhängigen Variable nicht randomisiert wurde. 
:::


## Multiple lineare Regression
In diesem Unterkapitel soll in die multiple Regression eingeführt werden. Dazu dient ebenfalls ein Erklärvideo gefolgt von Aufgaben.

### Erklärvideo
<div style="padding:56.25% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/910769054?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" style="position:absolute;top:0;left:0;width:100%;height:100%;" title="Zusammenhang zweier metrischer Variablen unter Kontrolle"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>

### Erklärvideo
Die standardisierten Steigungskoeffizeinten $\beta_i$ stellen ja eine Effektstärke der partiellen Assoziation des Prädiktors $i$ mit der abhängigen Variable dar. Nimmt man mehrere Prädiktoren auf, kann der Determinationskoeffizient $R^2$ eine Effektstärke für die Güte des Gesamtmodells darstellen.
<div style="padding:56.25% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/910768944?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" style="position:absolute;top:0;left:0;width:100%;height:100%;" title="Determinationsoeffizient_Erklaervideo"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>


### Worked Out Example
In der Übungsaufgabe zur einfachen linearen Regression haben wir vermutet, dass Einschätzung von Effort und Value durch die Lehrkraft von der Leistung der Lernenden gefärbt sein könnte. Wäre dem so, sollte man ein Sinken der Prädiktionskraft des Prädiktors Value nach Adjustierung um die Vorjahresleistung beobachten.
```{r}
tab_model(
    lm(g4tmathss ~ g4ptvalu, data = data_star_sampled),
    lm(g4tmathss ~ g4ptvalu + g3tmathss, data = data_star_sampled),
    show.ci = F, show.std = T
)
```

Dies ist tatsächlich der Fall. Der standardisierte Regressionskoeffizient sinkt von .35 auf .12.

## Aufgabe
::: {.panel-tabset}

### Aufgabe
Untersucht, inwiefern die ebenfalls Lehrer:inneingeschätzte Variable `Initiative` (z.B. "*participates actively in class discussions*") `g4ptinit` die Mathematikleistung in Klasse 4 `g4tmathss` prädiziert und inwiefern sich der Effekt nach Adjustierung der Vortestleistung `g3tmathss` ändert

### Lösungshinweise
```{r}
#| results: hide

lm(g4tmathss ~ g4ptinit, data = data_star_sampled)
lm(g4tmathss ~ g4ptinit + g3tmathss, data = data_star_sampled)
```


### Lösung
```{r}
tab_model(
    lm(g4tmathss ~ g4ptinit, data = data_star_sampled),
    lm(g4tmathss ~ g4ptinit + g3tmathss, data = data_star_sampled),
    show.std = T, show.ci = F)
```

Der standardisierte Regressionskoeffizient der Initiative-Skala ist mit .49 groß ausgeprägt.
Nach Adjustierung um die Vorjahrestestleistung, sinkt die prädiktive Kraft deutlich, es ist aber weiterhin ein substantieller Effekt zu beobachten.
:::

## Weiterführende Literatur
:::{.callout-note collapse=false appearance='default' icon=true}
## Literaturempfehlungen zum Thema Regression
* Eid, M., Gollwitzer, M., & Schmitt, M. (2013). Statistik und Forschungsmethoden: Lehrbuch. Mit Online-Materialien (3. Aufl.). Beltz.
* Gelman, A., Hill, J., & Vehtari, A. (2020). Regression and Other Stories (1. Aufl.). Cambridge University Press. https://doi.org/10.1017/9781139161879
:::


